{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from utils import *\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/datadrive/data_cs/'\n",
    "batch_size = 256\n",
    "batch_num  = 128\n",
    "epoch_num  = 100\n",
    "samp_num   = 7\n",
    "\n",
    "device = torch.device(\"cuda:3\")\n",
    "graph = dill.load(open(data_dir + 'graph.pk', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_range = {t: True for t in graph.times if t != None and t < 2015}\n",
    "valid_range = {t: True for t in graph.times if t != None and t >= 2015  and t <= 2016}\n",
    "test_range  = {t: True for t in graph.times if t != None and t > 2016}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pf_sample(seed, papers, pairs, t_range, batch_size, test = False):\n",
    "    np.random.seed(seed)\n",
    "    _time = np.random.choice(list(papers.keys()))\n",
    "    sampn = min(len(papers[_time]), batch_size)\n",
    "    pids = np.array(papers[_time])[np.random.choice(len(papers[_time]), sampn, replace = False)]\n",
    "    fids = []\n",
    "    edge = defaultdict(lambda: {})\n",
    "    for x_id, p_id in enumerate(pids):\n",
    "        f_ids = pairs[p_id]\n",
    "        for f_id in f_ids:\n",
    "            if f_id not in fids:\n",
    "                fids += [f_id]\n",
    "    pids = np.stack([pids, np.repeat([_time], sampn)]).T\n",
    "    fids = np.stack([fids, np.repeat([_time], len(fids))]).T\n",
    " \n",
    "    feature, times, edge_list, _, _ = sample_subgraph(graph, t_range, \\\n",
    "                inp = {'paper': pids, 'field': fids}, sampled_depth = 4, sampled_number = 100)\n",
    "\n",
    "    el = []\n",
    "    for i in edge_list['paper']['field']['rev_PF_in_L2']:\n",
    "        if i[0] < len(pids):\n",
    "            continue\n",
    "        el += [i]\n",
    "    edge_list['paper']['field']['rev_PF_in_L2'] = el\n",
    "\n",
    "    el = []\n",
    "    for i in edge_list['field']['paper']['PF_in_L2']:\n",
    "        if i[1] < len(pids):\n",
    "            continue\n",
    "        el += [i]\n",
    "    edge_list['field']['paper']['PF_in_L2'] = el\n",
    "    \n",
    "    \n",
    "    node_feature, node_type, edge_time, edge_index, edge_type, node_dict, edge_dict = \\\n",
    "            to_torch(feature, times, edge_list, graph)\n",
    "    '''\n",
    "        Trace the paper_id and field_id by its own index plus the type start index\n",
    "    '''\n",
    "    paper_ids = np.arange(len(pids)) + node_dict['paper'][0]\n",
    "    field_ids = np.arange(len(fids)) + node_dict['field'][0]\n",
    "    ylabel = torch.zeros(sampn, len(cand_list))\n",
    "    for x_id, p_id in enumerate(pids[:,0]):\n",
    "        for f_id in pairs[p_id]:\n",
    "            ylabel[x_id][cand_list.index(f_id)] = 1\n",
    "    ylabel /= ylabel.sum(axis=1).view(-1, 1)\n",
    "    return node_feature, node_type, edge_time, edge_index, edge_type, field_ids, paper_ids, ylabel\n",
    "    \n",
    "def prepare_data(pool, process_ids, train_papers, valid_papers):\n",
    "    jobs = []\n",
    "    for process_id in process_ids[:-1]:\n",
    "        p = pool.apply_async(pf_sample, args=(np.random.randint(2**32 - 1), train_papers, \\\n",
    "                                               train_pairs, train_range, batch_size))\n",
    "        jobs.append(p)\n",
    "    p = pool.apply_async(pf_sample, args=(np.random.randint(2**32 - 1), valid_papers, \\\n",
    "                                           valid_pairs, valid_range, batch_size))\n",
    "    jobs.append(p)\n",
    "    return jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(nn.Module):\n",
    "    def __init__(self, in_dim, n_hid, num_types, num_relations, n_heads, n_layers, dropout = 0.3):\n",
    "        super(GNN, self).__init__()\n",
    "        self.gcs = nn.ModuleList()\n",
    "        self.num_types = num_types\n",
    "        self.in_dim    = in_dim\n",
    "        self.n_hid     = n_hid\n",
    "        self.aggregat_ws   = nn.ModuleList()\n",
    "        self.drop          = nn.Dropout(dropout)\n",
    "        for t in range(num_types):\n",
    "            self.aggregat_ws.append(nn.Linear(in_dim, n_hid))\n",
    "        for l in range(n_layers):\n",
    "            self.gcs.append(RAGCNConv(n_hid, n_hid, num_types, num_relations, n_heads, dropout))\n",
    "    def set_device(self, device):\n",
    "        self.device = device\n",
    "        for gc in self.gcs:\n",
    "            gc.device = device\n",
    "    def forward(self, node_feature, node_type, edge_time, edge_index, edge_type):\n",
    "        res = torch.zeros(node_feature.size(0), self.n_hid).to(node_feature.device)\n",
    "        for t_id in range(self.num_types):\n",
    "            aggregat_w = self.aggregat_ws[t_id]\n",
    "            idx = (node_type == t_id)\n",
    "            if idx.sum() == 0:\n",
    "                continue\n",
    "            res[idx] = torch.tanh(aggregat_w(node_feature[idx]))\n",
    "        meta_xs = self.drop(res)\n",
    "        del res\n",
    "        for gc in self.gcs:\n",
    "            meta_xs = gc(meta_xs, node_type, edge_index, edge_type, edge_time)\n",
    "        return meta_xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Paper-Field\n",
    "'''\n",
    "paper_ser = {}\n",
    "\n",
    "train_pairs = {}\n",
    "valid_pairs = {}\n",
    "test_pairs  = {}\n",
    "\n",
    "train_papers = {_time: {} for _time in train_range}\n",
    "valid_papers = {_time: {} for _time in valid_range}\n",
    "test_papers  = {_time: {} for _time in test_range}\n",
    "\n",
    "for f_id in graph.edge_list['field']['paper']['PF_in_L2']:\n",
    "    for p_id in graph.edge_list['field']['paper']['PF_in_L2'][f_id]:\n",
    "        _time = graph.edge_list['field']['paper']['PF_in_L2'][f_id][p_id]\n",
    "        if _time in train_range:\n",
    "            if p_id not in train_pairs:\n",
    "                train_pairs[p_id] = []\n",
    "            train_pairs[p_id] += [f_id]\n",
    "            train_papers[_time][p_id] = True\n",
    "        elif _time in valid_range:\n",
    "            if p_id not in valid_pairs:\n",
    "                valid_pairs[p_id] = []\n",
    "            valid_pairs[p_id] += [f_id]\n",
    "            valid_papers[_time][p_id] = True\n",
    "        else:\n",
    "            if p_id not in test_pairs:\n",
    "                test_pairs[p_id] = []\n",
    "            test_pairs[p_id] += [f_id]\n",
    "            test_papers[_time][p_id] = True\n",
    "for _time in list(train_papers.keys()):\n",
    "    if len(train_papers[_time]) < batch_size // 2:\n",
    "        train_papers.pop(_time)\n",
    "    else:\n",
    "        train_papers[_time] = np.array(list(train_papers[_time].keys()))\n",
    "for _time in list(valid_papers.keys()):\n",
    "    if len(valid_papers[_time]) < batch_size // 2:\n",
    "        valid_papers.pop(_time)\n",
    "    else:\n",
    "        valid_papers[_time] = np.array(list(valid_papers[_time].keys()))\n",
    "for _time in list(test_papers.keys()):\n",
    "    if len(test_papers[_time]) < batch_size // 2:\n",
    "        test_papers.pop(_time)\n",
    "    else:\n",
    "        test_papers[_time] = np.array(list(test_papers[_time].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = graph.get_types()\n",
    "cand_list = list(graph.edge_list['field']['paper']['PF_in_L2'])\n",
    "gnn = GNN(in_dim = len(graph.node_feature['paper']['emb'][0]) + 401, n_hid = 256, num_types = len(types), \\\n",
    "          num_relations = len(graph.get_meta_graph()) + 1, n_heads = 8, n_layers = 4).to(device)\n",
    "gnn = torch.load('../pre-train/save/mt_model.pt').to(device)\n",
    "classifier = Classifier(256, len(cand_list)).to(device)\n",
    "model = nn.Sequential(gnn, classifier)\n",
    "optimizer = torch.optim.AdamW(model.parameters())\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 1000, eta_min=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_train_papers = {}\n",
    "for _time in train_papers:\n",
    "    pid = train_papers[_time]\n",
    "    pid = pid[np.random.choice(np.arange(len(pid)), len(pid) // 10, replace=False)]\n",
    "    if len(pid) >= batch_size // 2:\n",
    "        sel_train_papers[_time] = pid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = []\n",
    "res = []\n",
    "best_val   = 0\n",
    "\n",
    "pool = mp.Pool(4)\n",
    "process_ids = np.arange(batch_num // 4)\n",
    "st = time.time()\n",
    "jobs = prepare_data(pool, process_ids, sel_train_papers, valid_papers)\n",
    "train_step = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Preparation: 94.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type GNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ModuleList. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type RAGCNConv. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BatchNorm. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type RelTemporalEncoding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Classifier. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 (115.4s)  LR: 0.00060 Train Loss: 7.40  Valid Loss: 6.46  Valid NDCG: 0.2066\n",
      "Data Preparation: 2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type GNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ModuleList. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type RAGCNConv. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BatchNorm. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type RelTemporalEncoding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Classifier. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 (112.8s)  LR: 0.00069 Train Loss: 6.17  Valid Loss: 6.40  Valid NDCG: 0.2093\n",
      "Data Preparation: 2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type GNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ModuleList. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type RAGCNConv. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BatchNorm. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type RelTemporalEncoding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Classifier. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 (113.0s)  LR: 0.00078 Train Loss: 6.02  Valid Loss: 6.17  Valid NDCG: 0.2375\n",
      "Data Preparation: 2.3s\n",
      "Epoch: 4 (111.6s)  LR: 0.00085 Train Loss: 5.96  Valid Loss: 6.13  Valid NDCG: 0.2307\n",
      "Data Preparation: 2.4s\n",
      "Epoch: 5 (110.7s)  LR: 0.00091 Train Loss: 5.85  Valid Loss: 6.30  Valid NDCG: 0.2181\n",
      "0.20911976395511278\n",
      "Data Preparation: 7.2s\n",
      "Epoch: 6 (112.6s)  LR: 0.00096 Train Loss: 5.79  Valid Loss: 6.05  Valid NDCG: 0.2319\n",
      "Data Preparation: 2.4s\n",
      "Epoch: 7 (111.6s)  LR: 0.00099 Train Loss: 5.71  Valid Loss: 6.31  Valid NDCG: 0.2256\n",
      "Data Preparation: 2.7s\n",
      "Epoch: 8 (112.0s)  LR: 0.00100 Train Loss: 5.71  Valid Loss: 6.19  Valid NDCG: 0.2313\n",
      "Data Preparation: 2.5s\n",
      "Epoch: 9 (111.8s)  LR: 0.00099 Train Loss: 5.62  Valid Loss: 6.00  Valid NDCG: 0.2364\n",
      "Data Preparation: 2.5s\n",
      "Epoch: 10 (112.0s)  LR: 0.00096 Train Loss: 5.59  Valid Loss: 6.07  Valid NDCG: 0.2254\n",
      "0.22829141039908102\n",
      "Data Preparation: 13.2s\n",
      "Epoch: 11 (112.5s)  LR: 0.00092 Train Loss: 5.55  Valid Loss: 6.11  Valid NDCG: 0.2339\n",
      "Data Preparation: 2.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type GNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ModuleList. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type RAGCNConv. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BatchNorm. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type RelTemporalEncoding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Classifier. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 (112.6s)  LR: 0.00086 Train Loss: 5.55  Valid Loss: 6.09  Valid NDCG: 0.2378\n",
      "Data Preparation: 2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type GNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ModuleList. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type RAGCNConv. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BatchNorm. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type RelTemporalEncoding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Classifier. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 (113.5s)  LR: 0.00079 Train Loss: 5.51  Valid Loss: 5.93  Valid NDCG: 0.2478\n",
      "Data Preparation: 2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type GNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ModuleList. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type RAGCNConv. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BatchNorm. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type RelTemporalEncoding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Classifier. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 (113.3s)  LR: 0.00070 Train Loss: 5.39  Valid Loss: 5.73  Valid NDCG: 0.2512\n",
      "Data Preparation: 2.7s\n",
      "Epoch: 15 (112.8s)  LR: 0.00061 Train Loss: 5.39  Valid Loss: 6.25  Valid NDCG: 0.2055\n",
      "0.25163706358561366\n",
      "Data Preparation: 7.6s\n",
      "Epoch: 16 (112.9s)  LR: 0.00051 Train Loss: 5.48  Valid Loss: 6.07  Valid NDCG: 0.2400\n",
      "Data Preparation: 2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type GNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ModuleList. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type RAGCNConv. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BatchNorm. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type RelTemporalEncoding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Classifier. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 (113.0s)  LR: 0.00042 Train Loss: 5.32  Valid Loss: 5.90  Valid NDCG: 0.2559\n",
      "Data Preparation: 2.5s\n",
      "Epoch: 18 (111.2s)  LR: 0.00032 Train Loss: 5.31  Valid Loss: 5.88  Valid NDCG: 0.2548\n",
      "Data Preparation: 2.4s\n",
      "Epoch: 19 (112.6s)  LR: 0.00024 Train Loss: 5.33  Valid Loss: 5.95  Valid NDCG: 0.2362\n",
      "Data Preparation: 2.5s\n",
      "Epoch: 20 (111.4s)  LR: 0.00016 Train Loss: 5.36  Valid Loss: 5.87  Valid NDCG: 0.2514\n",
      "0.22481632790788486\n",
      "Data Preparation: 7.7s\n",
      "Epoch: 21 (112.3s)  LR: 0.00009 Train Loss: 5.40  Valid Loss: 5.95  Valid NDCG: 0.2430\n",
      "Data Preparation: 2.5s\n",
      "Epoch: 22 (112.4s)  LR: 0.00005 Train Loss: 5.31  Valid Loss: 5.91  Valid NDCG: 0.2402\n",
      "Data Preparation: 2.7s\n",
      "Epoch: 23 (111.3s)  LR: 0.00001 Train Loss: 5.31  Valid Loss: 5.99  Valid NDCG: 0.2433\n",
      "Data Preparation: 2.8s\n",
      "Epoch: 24 (111.4s)  LR: 0.00000 Train Loss: 5.30  Valid Loss: 6.06  Valid NDCG: 0.2314\n",
      "Data Preparation: 2.6s\n",
      "Epoch: 25 (112.9s)  LR: 0.00001 Train Loss: 5.34  Valid Loss: 5.62  Valid NDCG: 0.2469\n",
      "0.21591237279007489\n",
      "Data Preparation: 13.1s\n",
      "Epoch: 26 (111.3s)  LR: 0.00003 Train Loss: 5.29  Valid Loss: 5.89  Valid NDCG: 0.2438\n",
      "Data Preparation: 2.7s\n",
      "Epoch: 27 (111.2s)  LR: 0.00007 Train Loss: 5.40  Valid Loss: 5.99  Valid NDCG: 0.2366\n",
      "Data Preparation: 2.4s\n",
      "Epoch: 28 (112.3s)  LR: 0.00013 Train Loss: 5.26  Valid Loss: 6.02  Valid NDCG: 0.2341\n",
      "Data Preparation: 2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type GNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ModuleList. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type RAGCNConv. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BatchNorm. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type RelTemporalEncoding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Classifier. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29 (112.9s)  LR: 0.00020 Train Loss: 5.27  Valid Loss: 5.77  Valid NDCG: 0.2617\n",
      "Data Preparation: 2.5s\n",
      "Epoch: 30 (112.7s)  LR: 0.00029 Train Loss: 5.30  Valid Loss: 5.88  Valid NDCG: 0.2557\n",
      "0.25172371790490744\n",
      "Data Preparation: 7.7s\n",
      "Epoch: 31 (112.5s)  LR: 0.00038 Train Loss: 5.19  Valid Loss: 5.91  Valid NDCG: 0.2369\n",
      "Data Preparation: 2.5s\n",
      "Epoch: 32 (112.7s)  LR: 0.00048 Train Loss: 5.27  Valid Loss: 5.85  Valid NDCG: 0.2450\n",
      "Data Preparation: 2.4s\n",
      "Epoch: 33 (112.6s)  LR: 0.00057 Train Loss: 5.31  Valid Loss: 5.86  Valid NDCG: 0.2411\n",
      "Data Preparation: 2.8s\n",
      "Epoch: 34 (112.3s)  LR: 0.00067 Train Loss: 5.29  Valid Loss: 5.93  Valid NDCG: 0.2465\n",
      "Data Preparation: 2.7s\n",
      "Epoch: 35 (110.6s)  LR: 0.00075 Train Loss: 5.22  Valid Loss: 5.95  Valid NDCG: 0.2428\n",
      "0.2602171257109083\n",
      "Data Preparation: 7.8s\n",
      "Epoch: 36 (113.0s)  LR: 0.00083 Train Loss: 5.24  Valid Loss: 6.31  Valid NDCG: 0.2187\n",
      "Data Preparation: 2.4s\n",
      "Epoch: 37 (112.4s)  LR: 0.00090 Train Loss: 5.26  Valid Loss: 6.03  Valid NDCG: 0.2259\n",
      "Data Preparation: 2.8s\n",
      "Epoch: 38 (112.9s)  LR: 0.00095 Train Loss: 5.25  Valid Loss: 5.98  Valid NDCG: 0.2520\n",
      "Data Preparation: 2.4s\n",
      "Epoch: 39 (112.6s)  LR: 0.00098 Train Loss: 5.25  Valid Loss: 6.10  Valid NDCG: 0.2283\n",
      "Data Preparation: 2.6s\n",
      "Epoch: 40 (116.7s)  LR: 0.00100 Train Loss: 5.23  Valid Loss: 5.81  Valid NDCG: 0.2411\n",
      "0.22205607316403214\n",
      "Data Preparation: 12.8s\n",
      "Epoch: 41 (155.7s)  LR: 0.00100 Train Loss: 5.23  Valid Loss: 5.89  Valid NDCG: 0.2572\n",
      "Data Preparation: 2.5s\n",
      "Epoch: 42 (176.4s)  LR: 0.00097 Train Loss: 5.09  Valid Loss: 5.87  Valid NDCG: 0.2557\n",
      "Data Preparation: 2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type GNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ModuleList. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type RAGCNConv. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BatchNorm. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type RelTemporalEncoding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Classifier. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43 (176.7s)  LR: 0.00093 Train Loss: 5.09  Valid Loss: 5.80  Valid NDCG: 0.2634\n",
      "Data Preparation: 2.9s\n",
      "Epoch: 44 (175.3s)  LR: 0.00088 Train Loss: 5.13  Valid Loss: 5.90  Valid NDCG: 0.2454\n",
      "Data Preparation: 3.2s\n",
      "Epoch: 45 (177.1s)  LR: 0.00081 Train Loss: 5.12  Valid Loss: 5.97  Valid NDCG: 0.2471\n",
      "0.23533486918338087\n",
      "Data Preparation: 9.4s\n",
      "Epoch: 46 (174.9s)  LR: 0.00072 Train Loss: 5.16  Valid Loss: 5.99  Valid NDCG: 0.2418\n",
      "Data Preparation: 2.9s\n",
      "Epoch: 47 (177.3s)  LR: 0.00063 Train Loss: 5.06  Valid Loss: 5.83  Valid NDCG: 0.2620\n",
      "Data Preparation: 2.9s\n",
      "Epoch: 48 (177.4s)  LR: 0.00054 Train Loss: 5.07  Valid Loss: 5.83  Valid NDCG: 0.2524\n",
      "Data Preparation: 2.6s\n",
      "Epoch: 49 (175.1s)  LR: 0.00044 Train Loss: 5.03  Valid Loss: 5.92  Valid NDCG: 0.2462\n",
      "Data Preparation: 2.6s\n",
      "Epoch: 50 (178.3s)  LR: 0.00035 Train Loss: 5.04  Valid Loss: 5.90  Valid NDCG: 0.2599\n",
      "0.25467404998078685\n",
      "Data Preparation: 13.3s\n",
      "Epoch: 51 (176.3s)  LR: 0.00026 Train Loss: 5.06  Valid Loss: 5.86  Valid NDCG: 0.2490\n",
      "Data Preparation: 2.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type GNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ModuleList. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type RAGCNConv. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BatchNorm. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type RelTemporalEncoding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Classifier. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 52 (174.6s)  LR: 0.00018 Train Loss: 5.05  Valid Loss: 5.64  Valid NDCG: 0.2712\n",
      "Data Preparation: 2.7s\n",
      "Epoch: 53 (176.5s)  LR: 0.00011 Train Loss: 5.02  Valid Loss: 5.84  Valid NDCG: 0.2463\n",
      "Data Preparation: 2.6s\n",
      "Epoch: 54 (173.0s)  LR: 0.00006 Train Loss: 5.03  Valid Loss: 6.03  Valid NDCG: 0.2477\n",
      "Data Preparation: 2.5s\n",
      "Epoch: 55 (174.0s)  LR: 0.00002 Train Loss: 5.06  Valid Loss: 6.11  Valid NDCG: 0.2419\n",
      "0.22905887913146702\n",
      "Data Preparation: 7.8s\n",
      "Epoch: 56 (164.0s)  LR: 0.00000 Train Loss: 5.08  Valid Loss: 6.08  Valid NDCG: 0.2382\n",
      "Data Preparation: 2.7s\n",
      "Epoch: 57 (177.7s)  LR: 0.00000 Train Loss: 5.02  Valid Loss: 5.76  Valid NDCG: 0.2636\n",
      "Data Preparation: 2.5s\n",
      "Epoch: 58 (170.7s)  LR: 0.00002 Train Loss: 5.01  Valid Loss: 6.19  Valid NDCG: 0.2346\n",
      "Data Preparation: 2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type GNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ModuleList. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type RAGCNConv. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BatchNorm. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type RelTemporalEncoding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Classifier. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 59 (172.4s)  LR: 0.00006 Train Loss: 5.04  Valid Loss: 5.64  Valid NDCG: 0.2732\n",
      "Data Preparation: 2.9s\n",
      "Epoch: 60 (175.5s)  LR: 0.00012 Train Loss: 5.13  Valid Loss: 5.87  Valid NDCG: 0.2586\n",
      "0.22685614839766957\n",
      "Data Preparation: 9.2s\n",
      "Epoch: 61 (168.6s)  LR: 0.00018 Train Loss: 5.05  Valid Loss: 5.79  Valid NDCG: 0.2584\n",
      "Data Preparation: 3.1s\n",
      "Epoch: 62 (176.4s)  LR: 0.00027 Train Loss: 5.10  Valid Loss: 5.83  Valid NDCG: 0.2389\n",
      "Data Preparation: 2.7s\n",
      "Epoch: 63 (175.6s)  LR: 0.00036 Train Loss: 4.98  Valid Loss: 6.10  Valid NDCG: 0.2392\n",
      "Data Preparation: 2.6s\n",
      "Epoch: 64 (175.0s)  LR: 0.00045 Train Loss: 4.88  Valid Loss: 5.74  Valid NDCG: 0.2536\n",
      "Data Preparation: 3.0s\n",
      "Epoch: 65 (155.8s)  LR: 0.00055 Train Loss: 5.17  Valid Loss: 5.83  Valid NDCG: 0.2534\n",
      "0.2369753825287796\n",
      "Data Preparation: 12.4s\n",
      "Epoch: 66 (118.9s)  LR: 0.00064 Train Loss: 4.90  Valid Loss: 6.16  Valid NDCG: 0.2297\n",
      "Data Preparation: 2.6s\n",
      "Epoch: 67 (171.0s)  LR: 0.00073 Train Loss: 5.01  Valid Loss: 5.84  Valid NDCG: 0.2432\n",
      "Data Preparation: 2.5s\n",
      "Epoch: 68 (174.7s)  LR: 0.00081 Train Loss: 5.02  Valid Loss: 5.94  Valid NDCG: 0.2471\n",
      "Data Preparation: 2.4s\n",
      "Epoch: 69 (175.2s)  LR: 0.00088 Train Loss: 5.00  Valid Loss: 5.97  Valid NDCG: 0.2384\n",
      "Data Preparation: 2.4s\n",
      "Epoch: 70 (177.7s)  LR: 0.00094 Train Loss: 5.23  Valid Loss: 5.83  Valid NDCG: 0.2542\n",
      "0.23731072896737931\n",
      "Data Preparation: 7.9s\n",
      "Epoch: 71 (176.0s)  LR: 0.00098 Train Loss: 4.97  Valid Loss: 5.81  Valid NDCG: 0.2560\n",
      "Data Preparation: 2.5s\n",
      "Epoch: 72 (174.3s)  LR: 0.00100 Train Loss: 5.14  Valid Loss: 5.87  Valid NDCG: 0.2482\n",
      "Data Preparation: 2.9s\n",
      "Epoch: 73 (178.3s)  LR: 0.00100 Train Loss: 4.89  Valid Loss: 6.00  Valid NDCG: 0.2346\n",
      "Data Preparation: 2.5s\n",
      "Epoch: 74 (175.9s)  LR: 0.00098 Train Loss: 5.00  Valid Loss: 5.71  Valid NDCG: 0.2653\n",
      "Data Preparation: 2.6s\n",
      "Epoch: 75 (174.5s)  LR: 0.00095 Train Loss: 5.35  Valid Loss: 5.99  Valid NDCG: 0.2442\n",
      "0.20965423623074322\n",
      "Data Preparation: 8.3s\n",
      "Epoch: 76 (174.5s)  LR: 0.00089 Train Loss: 5.05  Valid Loss: 5.80  Valid NDCG: 0.2461\n",
      "Data Preparation: 2.7s\n",
      "Epoch: 77 (178.4s)  LR: 0.00083 Train Loss: 5.00  Valid Loss: 5.87  Valid NDCG: 0.2371\n",
      "Data Preparation: 2.5s\n",
      "Epoch: 78 (179.4s)  LR: 0.00075 Train Loss: 4.89  Valid Loss: 5.97  Valid NDCG: 0.2366\n",
      "Data Preparation: 2.6s\n",
      "Epoch: 79 (176.7s)  LR: 0.00066 Train Loss: 4.67  Valid Loss: 6.01  Valid NDCG: 0.2329\n",
      "Data Preparation: 2.9s\n",
      "Epoch: 80 (177.0s)  LR: 0.00056 Train Loss: 4.84  Valid Loss: 5.93  Valid NDCG: 0.2494\n",
      "0.22639482123233653\n",
      "Data Preparation: 13.2s\n",
      "Epoch: 81 (178.2s)  LR: 0.00047 Train Loss: 4.97  Valid Loss: 6.10  Valid NDCG: 0.2347\n",
      "Data Preparation: 2.6s\n",
      "Epoch: 82 (179.7s)  LR: 0.00037 Train Loss: 4.93  Valid Loss: 6.02  Valid NDCG: 0.2250\n",
      "Data Preparation: 3.0s\n",
      "Epoch: 83 (179.8s)  LR: 0.00028 Train Loss: 5.26  Valid Loss: 5.98  Valid NDCG: 0.2396\n",
      "Data Preparation: 3.0s\n",
      "Epoch: 84 (177.9s)  LR: 0.00020 Train Loss: 5.01  Valid Loss: 5.89  Valid NDCG: 0.2427\n",
      "Data Preparation: 2.5s\n",
      "Epoch: 85 (177.3s)  LR: 0.00013 Train Loss: 5.03  Valid Loss: 6.00  Valid NDCG: 0.2317\n",
      "0.23835381452480997\n",
      "Data Preparation: 8.3s\n",
      "Epoch: 86 (175.8s)  LR: 0.00007 Train Loss: 4.86  Valid Loss: 6.12  Valid NDCG: 0.2262\n",
      "Data Preparation: 2.5s\n",
      "Epoch: 87 (181.5s)  LR: 0.00003 Train Loss: 4.62  Valid Loss: 5.81  Valid NDCG: 0.2364\n",
      "Data Preparation: 2.5s\n",
      "Epoch: 88 (177.6s)  LR: 0.00001 Train Loss: 4.93  Valid Loss: 6.04  Valid NDCG: 0.2350\n",
      "Data Preparation: 2.5s\n",
      "Epoch: 89 (178.6s)  LR: 0.00000 Train Loss: 4.88  Valid Loss: 6.04  Valid NDCG: 0.2344\n",
      "Data Preparation: 2.9s\n",
      "Epoch: 90 (174.8s)  LR: 0.00002 Train Loss: 5.01  Valid Loss: 6.04  Valid NDCG: 0.2348\n",
      "0.2371444393328592\n",
      "Data Preparation: 8.4s\n",
      "Epoch: 91 (173.4s)  LR: 0.00005 Train Loss: 5.00  Valid Loss: 6.09  Valid NDCG: 0.2321\n",
      "Data Preparation: 2.8s\n",
      "Epoch: 92 (179.0s)  LR: 0.00010 Train Loss: 5.03  Valid Loss: 5.94  Valid NDCG: 0.2458\n",
      "Data Preparation: 2.7s\n",
      "Epoch: 93 (179.5s)  LR: 0.00017 Train Loss: 4.83  Valid Loss: 5.69  Valid NDCG: 0.2596\n",
      "Data Preparation: 2.5s\n",
      "Epoch: 94 (180.0s)  LR: 0.00024 Train Loss: 4.88  Valid Loss: 6.05  Valid NDCG: 0.2376\n",
      "Data Preparation: 2.6s\n",
      "Epoch: 95 (179.9s)  LR: 0.00033 Train Loss: 4.82  Valid Loss: 5.92  Valid NDCG: 0.2438\n",
      "0.22456323907414982\n",
      "Data Preparation: 13.9s\n",
      "Epoch: 96 (174.4s)  LR: 0.00043 Train Loss: 5.08  Valid Loss: 5.93  Valid NDCG: 0.2467\n",
      "Data Preparation: 3.0s\n",
      "Epoch: 97 (178.5s)  LR: 0.00052 Train Loss: 4.87  Valid Loss: 5.92  Valid NDCG: 0.2513\n",
      "Data Preparation: 3.0s\n",
      "Epoch: 98 (175.5s)  LR: 0.00062 Train Loss: 4.96  Valid Loss: 5.81  Valid NDCG: 0.2482\n",
      "Data Preparation: 2.6s\n",
      "Epoch: 99 (176.4s)  LR: 0.00071 Train Loss: 4.98  Valid Loss: 6.21  Valid NDCG: 0.2298\n",
      "Data Preparation: 2.6s\n",
      "Epoch: 100 (172.8s)  LR: 0.00079 Train Loss: 4.78  Valid Loss: 5.76  Valid NDCG: 0.2609\n",
      "0.23099966686124224\n",
      "Data Preparation: 8.3s\n",
      "Epoch: 101 (174.0s)  LR: 0.00087 Train Loss: 4.98  Valid Loss: 5.84  Valid NDCG: 0.2425\n",
      "Data Preparation: 3.1s\n",
      "Epoch: 102 (177.7s)  LR: 0.00093 Train Loss: 5.01  Valid Loss: 6.01  Valid NDCG: 0.2438\n",
      "Data Preparation: 2.9s\n",
      "Epoch: 103 (177.6s)  LR: 0.00097 Train Loss: 4.83  Valid Loss: 6.21  Valid NDCG: 0.2307\n",
      "Data Preparation: 2.8s\n",
      "Epoch: 104 (178.1s)  LR: 0.00099 Train Loss: 4.82  Valid Loss: 6.57  Valid NDCG: 0.2066\n",
      "Data Preparation: 2.6s\n",
      "Epoch: 105 (175.6s)  LR: 0.00100 Train Loss: 4.77  Valid Loss: 6.03  Valid NDCG: 0.2326\n",
      "0.22280356084373715\n",
      "Data Preparation: 13.4s\n",
      "Epoch: 106 (172.2s)  LR: 0.00099 Train Loss: 4.76  Valid Loss: 6.05  Valid NDCG: 0.2334\n",
      "Data Preparation: 3.4s\n",
      "Epoch: 107 (176.9s)  LR: 0.00096 Train Loss: 4.82  Valid Loss: 5.85  Valid NDCG: 0.2572\n",
      "Data Preparation: 3.4s\n",
      "Epoch: 108 (175.8s)  LR: 0.00091 Train Loss: 5.12  Valid Loss: 6.11  Valid NDCG: 0.2264\n",
      "Data Preparation: 2.6s\n",
      "Epoch: 109 (178.3s)  LR: 0.00084 Train Loss: 4.94  Valid Loss: 6.10  Valid NDCG: 0.2392\n",
      "Data Preparation: 2.6s\n",
      "Epoch: 110 (177.9s)  LR: 0.00077 Train Loss: 5.04  Valid Loss: 5.99  Valid NDCG: 0.2429\n",
      "0.22310074079344566\n",
      "Data Preparation: 8.2s\n",
      "Epoch: 111 (171.6s)  LR: 0.00068 Train Loss: 4.69  Valid Loss: 6.33  Valid NDCG: 0.2170\n",
      "Data Preparation: 2.6s\n",
      "Epoch: 112 (178.1s)  LR: 0.00059 Train Loss: 4.89  Valid Loss: 5.86  Valid NDCG: 0.2473\n",
      "Data Preparation: 2.9s\n",
      "Epoch: 113 (174.9s)  LR: 0.00049 Train Loss: 4.86  Valid Loss: 6.12  Valid NDCG: 0.2230\n",
      "Data Preparation: 2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type GNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ModuleList. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type RAGCNConv. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BatchNorm. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type RelTemporalEncoding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Classifier. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 114 (179.3s)  LR: 0.00039 Train Loss: 4.73  Valid Loss: 5.57  Valid NDCG: 0.2817\n",
      "Data Preparation: 2.7s\n",
      "Epoch: 115 (179.8s)  LR: 0.00030 Train Loss: 4.74  Valid Loss: 6.35  Valid NDCG: 0.2282\n",
      "0.22918068716989223\n",
      "Data Preparation: 8.0s\n",
      "Epoch: 116 (174.3s)  LR: 0.00022 Train Loss: 4.77  Valid Loss: 6.37  Valid NDCG: 0.2301\n",
      "Data Preparation: 2.7s\n",
      "Epoch: 117 (172.3s)  LR: 0.00014 Train Loss: 4.76  Valid Loss: 6.17  Valid NDCG: 0.2357\n",
      "Data Preparation: 2.7s\n",
      "Epoch: 118 (175.0s)  LR: 0.00008 Train Loss: 4.96  Valid Loss: 6.41  Valid NDCG: 0.2125\n",
      "Data Preparation: 2.7s\n",
      "Epoch: 119 (177.4s)  LR: 0.00004 Train Loss: 4.92  Valid Loss: 6.02  Valid NDCG: 0.2417\n",
      "Data Preparation: 2.6s\n",
      "Epoch: 120 (175.6s)  LR: 0.00001 Train Loss: 4.65  Valid Loss: 6.14  Valid NDCG: 0.2308\n",
      "0.22571512619416986\n",
      "Data Preparation: 13.8s\n",
      "Epoch: 121 (167.4s)  LR: 0.00000 Train Loss: 4.87  Valid Loss: 6.13  Valid NDCG: 0.2330\n",
      "Data Preparation: 2.6s\n",
      "Epoch: 122 (177.4s)  LR: 0.00001 Train Loss: 4.70  Valid Loss: 6.31  Valid NDCG: 0.2178\n",
      "Data Preparation: 2.4s\n",
      "Epoch: 123 (177.5s)  LR: 0.00004 Train Loss: 4.89  Valid Loss: 5.98  Valid NDCG: 0.2224\n",
      "Data Preparation: 2.6s\n",
      "Epoch: 124 (178.0s)  LR: 0.00009 Train Loss: 4.92  Valid Loss: 6.20  Valid NDCG: 0.2255\n",
      "Data Preparation: 3.0s\n",
      "Epoch: 125 (179.6s)  LR: 0.00015 Train Loss: 4.94  Valid Loss: 6.32  Valid NDCG: 0.2202\n",
      "0.24600510761244992\n",
      "Data Preparation: 9.0s\n",
      "Epoch: 126 (171.1s)  LR: 0.00022 Train Loss: 4.63  Valid Loss: 6.15  Valid NDCG: 0.2203\n",
      "Data Preparation: 3.3s\n",
      "Epoch: 127 (178.0s)  LR: 0.00031 Train Loss: 4.77  Valid Loss: 6.17  Valid NDCG: 0.2234\n",
      "Data Preparation: 2.7s\n",
      "Epoch: 128 (178.2s)  LR: 0.00040 Train Loss: 4.93  Valid Loss: 6.37  Valid NDCG: 0.2100\n",
      "Data Preparation: 2.8s\n",
      "Epoch: 129 (177.9s)  LR: 0.00050 Train Loss: 4.94  Valid Loss: 5.94  Valid NDCG: 0.2441\n",
      "Data Preparation: 2.8s\n",
      "Epoch: 130 (180.2s)  LR: 0.00059 Train Loss: 4.53  Valid Loss: 6.11  Valid NDCG: 0.2329\n",
      "0.22923193252794413\n",
      "Data Preparation: 8.9s\n",
      "Epoch: 131 (168.5s)  LR: 0.00069 Train Loss: 4.62  Valid Loss: 6.06  Valid NDCG: 0.2203\n",
      "Data Preparation: 2.7s\n",
      "Epoch: 132 (176.8s)  LR: 0.00077 Train Loss: 4.80  Valid Loss: 6.40  Valid NDCG: 0.2077\n",
      "Data Preparation: 3.2s\n",
      "Epoch: 133 (176.3s)  LR: 0.00085 Train Loss: 4.81  Valid Loss: 6.37  Valid NDCG: 0.2069\n",
      "Data Preparation: 2.4s\n",
      "Epoch: 134 (179.2s)  LR: 0.00091 Train Loss: 4.68  Valid Loss: 6.22  Valid NDCG: 0.2213\n",
      "Data Preparation: 2.8s\n",
      "Epoch: 135 (173.9s)  LR: 0.00096 Train Loss: 4.64  Valid Loss: 6.21  Valid NDCG: 0.2244\n",
      "0.2450224401237002\n",
      "Data Preparation: 14.8s\n",
      "Epoch: 136 (172.2s)  LR: 0.00099 Train Loss: 4.52  Valid Loss: 6.05  Valid NDCG: 0.2381\n",
      "Data Preparation: 2.6s\n",
      "Epoch: 137 (176.6s)  LR: 0.00100 Train Loss: 4.70  Valid Loss: 6.31  Valid NDCG: 0.2158\n",
      "Data Preparation: 3.2s\n",
      "Epoch: 138 (175.7s)  LR: 0.00099 Train Loss: 4.86  Valid Loss: 6.06  Valid NDCG: 0.2351\n",
      "Data Preparation: 3.3s\n",
      "Epoch: 139 (173.9s)  LR: 0.00097 Train Loss: 4.91  Valid Loss: 6.19  Valid NDCG: 0.2146\n",
      "Data Preparation: 2.9s\n",
      "Epoch: 140 (178.3s)  LR: 0.00092 Train Loss: 4.78  Valid Loss: 6.13  Valid NDCG: 0.2340\n",
      "0.21755636572246506\n",
      "Data Preparation: 8.2s\n",
      "Epoch: 141 (176.1s)  LR: 0.00086 Train Loss: 4.55  Valid Loss: 6.11  Valid NDCG: 0.2273\n",
      "Data Preparation: 3.2s\n",
      "Epoch: 142 (176.0s)  LR: 0.00079 Train Loss: 4.65  Valid Loss: 5.95  Valid NDCG: 0.2414\n",
      "Data Preparation: 3.0s\n",
      "Epoch: 143 (180.4s)  LR: 0.00070 Train Loss: 4.82  Valid Loss: 5.75  Valid NDCG: 0.2609\n",
      "Data Preparation: 2.7s\n",
      "Epoch: 144 (175.3s)  LR: 0.00061 Train Loss: 4.74  Valid Loss: 5.83  Valid NDCG: 0.2720\n",
      "Data Preparation: 2.6s\n",
      "Epoch: 145 (179.8s)  LR: 0.00052 Train Loss: 4.83  Valid Loss: 5.89  Valid NDCG: 0.2529\n",
      "0.22396903463935824\n",
      "Data Preparation: 13.8s\n",
      "Epoch: 146 (169.6s)  LR: 0.00042 Train Loss: 4.46  Valid Loss: 6.19  Valid NDCG: 0.2322\n",
      "Data Preparation: 2.5s\n",
      "Epoch: 147 (178.2s)  LR: 0.00033 Train Loss: 4.72  Valid Loss: 5.96  Valid NDCG: 0.2471\n",
      "Data Preparation: 2.5s\n",
      "Epoch: 148 (174.3s)  LR: 0.00024 Train Loss: 4.80  Valid Loss: 6.13  Valid NDCG: 0.2305\n",
      "Data Preparation: 2.6s\n",
      "Epoch: 149 (175.1s)  LR: 0.00016 Train Loss: 4.52  Valid Loss: 6.20  Valid NDCG: 0.2240\n",
      "Data Preparation: 2.6s\n",
      "Epoch: 150 (177.1s)  LR: 0.00010 Train Loss: 4.50  Valid Loss: 5.73  Valid NDCG: 0.2571\n",
      "0.2326838716145742\n",
      "Data Preparation: 8.2s\n",
      "Epoch: 151 (169.7s)  LR: 0.00005 Train Loss: 4.56  Valid Loss: 6.15  Valid NDCG: 0.2314\n",
      "Data Preparation: 2.5s\n",
      "Epoch: 152 (176.2s)  LR: 0.00002 Train Loss: 4.78  Valid Loss: 5.82  Valid NDCG: 0.2477\n",
      "Data Preparation: 2.5s\n",
      "Epoch: 153 (177.4s)  LR: 0.00000 Train Loss: 4.69  Valid Loss: 5.99  Valid NDCG: 0.2450\n",
      "Data Preparation: 2.6s\n",
      "Epoch: 154 (177.3s)  LR: 0.00001 Train Loss: 4.70  Valid Loss: 5.75  Valid NDCG: 0.2720\n",
      "Data Preparation: 2.8s\n",
      "Epoch: 155 (176.8s)  LR: 0.00003 Train Loss: 4.63  Valid Loss: 6.27  Valid NDCG: 0.2250\n",
      "0.2337623726066342\n",
      "Data Preparation: 8.7s\n",
      "Epoch: 156 (175.4s)  LR: 0.00007 Train Loss: 4.82  Valid Loss: 6.18  Valid NDCG: 0.2266\n",
      "Data Preparation: 2.6s\n",
      "Epoch: 157 (179.6s)  LR: 0.00013 Train Loss: 4.56  Valid Loss: 6.05  Valid NDCG: 0.2491\n",
      "Data Preparation: 2.7s\n",
      "Epoch: 158 (176.8s)  LR: 0.00020 Train Loss: 4.70  Valid Loss: 6.05  Valid NDCG: 0.2325\n",
      "Data Preparation: 3.2s\n",
      "Epoch: 159 (176.4s)  LR: 0.00028 Train Loss: 4.65  Valid Loss: 5.85  Valid NDCG: 0.2455\n",
      "Data Preparation: 3.0s\n",
      "Epoch: 160 (176.7s)  LR: 0.00038 Train Loss: 4.80  Valid Loss: 5.99  Valid NDCG: 0.2365\n",
      "0.24565385884693725\n",
      "Data Preparation: 13.6s\n",
      "Epoch: 161 (175.8s)  LR: 0.00047 Train Loss: 4.73  Valid Loss: 6.11  Valid NDCG: 0.2215\n",
      "Data Preparation: 3.0s\n",
      "Epoch: 162 (176.6s)  LR: 0.00057 Train Loss: 4.77  Valid Loss: 6.25  Valid NDCG: 0.2338\n",
      "Data Preparation: 2.7s\n",
      "Epoch: 163 (180.3s)  LR: 0.00066 Train Loss: 4.78  Valid Loss: 6.36  Valid NDCG: 0.2238\n",
      "Data Preparation: 3.1s\n",
      "Epoch: 164 (175.5s)  LR: 0.00075 Train Loss: 4.62  Valid Loss: 5.82  Valid NDCG: 0.2508\n",
      "Data Preparation: 2.7s\n",
      "Epoch: 165 (176.4s)  LR: 0.00083 Train Loss: 4.56  Valid Loss: 5.92  Valid NDCG: 0.2541\n",
      "0.24287123128218482\n",
      "Data Preparation: 8.3s\n",
      "Epoch: 166 (173.4s)  LR: 0.00090 Train Loss: 4.76  Valid Loss: 6.19  Valid NDCG: 0.2236\n",
      "Data Preparation: 3.2s\n",
      "Epoch: 167 (179.2s)  LR: 0.00095 Train Loss: 4.56  Valid Loss: 6.18  Valid NDCG: 0.2201\n",
      "Data Preparation: 2.5s\n",
      "Epoch: 168 (178.0s)  LR: 0.00098 Train Loss: 4.79  Valid Loss: 6.17  Valid NDCG: 0.2309\n",
      "Data Preparation: 3.0s\n",
      "Epoch: 169 (178.6s)  LR: 0.00100 Train Loss: 4.92  Valid Loss: 6.16  Valid NDCG: 0.2338\n",
      "Data Preparation: 2.8s\n",
      "Epoch: 170 (177.2s)  LR: 0.00100 Train Loss: 4.68  Valid Loss: 6.21  Valid NDCG: 0.2383\n",
      "0.2553418701497023\n",
      "Data Preparation: 13.3s\n",
      "Epoch: 171 (169.1s)  LR: 0.00097 Train Loss: 4.75  Valid Loss: 6.27  Valid NDCG: 0.2234\n",
      "Data Preparation: 2.7s\n",
      "Epoch: 172 (179.5s)  LR: 0.00094 Train Loss: 4.56  Valid Loss: 6.14  Valid NDCG: 0.2296\n",
      "Data Preparation: 2.7s\n",
      "Epoch: 173 (178.5s)  LR: 0.00088 Train Loss: 4.49  Valid Loss: 6.64  Valid NDCG: 0.2229\n",
      "Data Preparation: 2.6s\n",
      "Epoch: 174 (173.0s)  LR: 0.00081 Train Loss: 4.51  Valid Loss: 6.11  Valid NDCG: 0.2390\n",
      "Data Preparation: 2.7s\n",
      "Epoch: 175 (176.5s)  LR: 0.00073 Train Loss: 4.55  Valid Loss: 6.23  Valid NDCG: 0.2323\n",
      "0.22124942816483845\n",
      "Data Preparation: 9.1s\n",
      "Epoch: 176 (174.2s)  LR: 0.00064 Train Loss: 4.64  Valid Loss: 5.92  Valid NDCG: 0.2379\n",
      "Data Preparation: 3.1s\n",
      "Epoch: 177 (179.8s)  LR: 0.00054 Train Loss: 4.64  Valid Loss: 6.14  Valid NDCG: 0.2268\n",
      "Data Preparation: 3.1s\n",
      "Epoch: 178 (177.8s)  LR: 0.00044 Train Loss: 4.72  Valid Loss: 6.26  Valid NDCG: 0.2251\n",
      "Data Preparation: 3.2s\n",
      "Epoch: 179 (178.3s)  LR: 0.00035 Train Loss: 4.70  Valid Loss: 6.46  Valid NDCG: 0.2098\n",
      "Data Preparation: 2.6s\n",
      "Epoch: 180 (175.2s)  LR: 0.00026 Train Loss: 4.64  Valid Loss: 6.30  Valid NDCG: 0.2271\n",
      "0.2366404534768949\n",
      "Data Preparation: 8.5s\n",
      "Epoch: 181 (170.9s)  LR: 0.00018 Train Loss: 4.73  Valid Loss: 5.98  Valid NDCG: 0.2383\n",
      "Data Preparation: 2.5s\n",
      "Epoch: 182 (175.8s)  LR: 0.00011 Train Loss: 4.51  Valid Loss: 6.06  Valid NDCG: 0.2340\n",
      "Data Preparation: 2.5s\n",
      "Epoch: 183 (178.2s)  LR: 0.00006 Train Loss: 4.54  Valid Loss: 6.26  Valid NDCG: 0.2221\n",
      "Data Preparation: 2.5s\n",
      "Epoch: 184 (172.2s)  LR: 0.00002 Train Loss: 4.24  Valid Loss: 6.20  Valid NDCG: 0.2323\n",
      "Data Preparation: 2.7s\n",
      "Epoch: 185 (177.7s)  LR: 0.00000 Train Loss: 4.69  Valid Loss: 6.07  Valid NDCG: 0.2219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23900581907530474\n",
      "Data Preparation: 13.5s\n",
      "Epoch: 186 (172.2s)  LR: 0.00000 Train Loss: 4.59  Valid Loss: 6.20  Valid NDCG: 0.2214\n",
      "Data Preparation: 2.6s\n",
      "Epoch: 187 (173.9s)  LR: 0.00002 Train Loss: 4.47  Valid Loss: 6.14  Valid NDCG: 0.2197\n",
      "Data Preparation: 2.5s\n",
      "Epoch: 188 (175.3s)  LR: 0.00006 Train Loss: 4.36  Valid Loss: 6.15  Valid NDCG: 0.2347\n",
      "Data Preparation: 2.9s\n",
      "Epoch: 189 (178.1s)  LR: 0.00011 Train Loss: 4.44  Valid Loss: 6.09  Valid NDCG: 0.2422\n",
      "Data Preparation: 2.5s\n",
      "Epoch: 190 (177.9s)  LR: 0.00018 Train Loss: 4.73  Valid Loss: 6.34  Valid NDCG: 0.2190\n",
      "0.23215874286078772\n",
      "Data Preparation: 9.2s\n",
      "Epoch: 191 (172.6s)  LR: 0.00026 Train Loss: 4.62  Valid Loss: 6.19  Valid NDCG: 0.2285\n",
      "Data Preparation: 2.8s\n",
      "Epoch: 192 (174.9s)  LR: 0.00035 Train Loss: 4.68  Valid Loss: 6.39  Valid NDCG: 0.2213\n",
      "Data Preparation: 2.7s\n",
      "Epoch: 193 (174.0s)  LR: 0.00045 Train Loss: 4.57  Valid Loss: 6.23  Valid NDCG: 0.2232\n",
      "Data Preparation: 2.8s\n",
      "Epoch: 194 (176.4s)  LR: 0.00054 Train Loss: 4.47  Valid Loss: 6.22  Valid NDCG: 0.2336\n",
      "Data Preparation: 2.7s\n",
      "Epoch: 195 (175.8s)  LR: 0.00064 Train Loss: 4.69  Valid Loss: 5.96  Valid NDCG: 0.2350\n",
      "0.21919516651165186\n",
      "Data Preparation: 7.9s\n",
      "Epoch: 196 (170.6s)  LR: 0.00073 Train Loss: 4.69  Valid Loss: 6.08  Valid NDCG: 0.2301\n",
      "Data Preparation: 2.7s\n",
      "Epoch: 197 (177.5s)  LR: 0.00081 Train Loss: 4.64  Valid Loss: 6.20  Valid NDCG: 0.2211\n",
      "Data Preparation: 2.6s\n",
      "Epoch: 198 (176.0s)  LR: 0.00088 Train Loss: 4.80  Valid Loss: 6.43  Valid NDCG: 0.2103\n",
      "Data Preparation: 2.7s\n",
      "Epoch: 199 (175.7s)  LR: 0.00094 Train Loss: 4.61  Valid Loss: 6.19  Valid NDCG: 0.2251\n",
      "Data Preparation: 2.6s\n",
      "Epoch: 200 (175.2s)  LR: 0.00098 Train Loss: 4.36  Valid Loss: 6.50  Valid NDCG: 0.2179\n",
      "0.2287464174998396\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.KLDivLoss(reduction='batchmean')\n",
    "for epoch in np.arange(200)+1:\n",
    "    '''\n",
    "        Prepare Training and Validation Data\n",
    "    '''\n",
    "    train_data = [job.get() for job in jobs[:-1]]\n",
    "    valid_data = jobs[-1].get()\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    pool = mp.Pool(4)\n",
    "    jobs = prepare_data(pool, process_ids, sel_train_papers, valid_papers)\n",
    "    et = time.time()\n",
    "    print('Data Preparation: %.1fs' % (et - st))\n",
    "    \n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    torch.cuda.empty_cache()\n",
    "    for batch in np.arange(2):\n",
    "        for node_feature, node_type, edge_time, edge_index, edge_type, field_ids, paper_ids, ylabel in train_data:\n",
    "            node_rep = gnn.forward(node_feature.to(device), node_type.to(device), \\\n",
    "                                   edge_time.to(device), edge_index.to(device), edge_type.to(device))\n",
    "            res  = classifier.forward(node_rep[paper_ids])\n",
    "            loss = criterion(res, ylabel.to(device))\n",
    "            optimizer.zero_grad() \n",
    "            torch.cuda.empty_cache()\n",
    "            loss.backward()\n",
    "            \n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.2)\n",
    "            optimizer.step()\n",
    "            train_losses += [loss.cpu().detach().tolist()]\n",
    "            train_step += 1\n",
    "            scheduler.step(train_step)\n",
    "            del res, loss\n",
    "    '''\n",
    "        Valid\n",
    "    '''\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        node_feature, node_type, edge_time, edge_index, edge_type, field_ids, paper_ids, ylabel = valid_data\n",
    "        node_rep = gnn.forward(node_feature.to(device), node_type.to(device), \\\n",
    "                                   edge_time.to(device), edge_index.to(device), edge_type.to(device))\n",
    "        res  = classifier.forward(node_rep[paper_ids])\n",
    "        loss = criterion(res, ylabel.to(device))\n",
    "        valid_res = []\n",
    "\n",
    "        for ai, bi in zip(ylabel, res.argsort(descending = True)):\n",
    "            valid_res += [ai[bi].tolist()]\n",
    "        valid_ndcg = np.average([ndcg_at_k(resi, len(resi)) for resi in valid_res])\n",
    "        if valid_ndcg > best_val:\n",
    "            best_val = valid_ndcg\n",
    "            torch.save(model, './save/rgt_3.pt')\n",
    "        st = time.time()\n",
    "        print((\"Epoch: %d (%.1fs)  LR: %.5f Train Loss: %.2f  Valid Loss: %.2f  Valid NDCG: %.4f\") % \\\n",
    "              (epoch, (st-et), optimizer.param_groups[0]['lr'], np.average(train_losses), loss.cpu().detach().tolist(),\\\n",
    "              valid_ndcg))\n",
    "        stats += [[np.average(train_losses), loss.cpu().detach().tolist()]]\n",
    "        del res, loss\n",
    "        if epoch % 5 == 0:\n",
    "            '''\n",
    "                Test\n",
    "            '''\n",
    "            _time = np.random.choice(list(test_papers.keys()))\n",
    "            node_feature, node_type, edge_time, edge_index, edge_type, field_ids, paper_ids, ylabel = pf_sample(np.random.randint(2 ** 32 - 1), test_papers, \\\n",
    "                                                           test_pairs, test_range, batch_size, test=True)\n",
    "            paper_rep = gnn.forward(node_feature.to(device), node_type.to(device), \\\n",
    "                      edge_time.to(device), edge_index.to(device), edge_type.to(device))[paper_ids]\n",
    "            res  = classifier.forward(paper_rep)\n",
    "            test_res = []\n",
    "            for ai, bi in zip(ylabel, res.argsort(descending = True)):\n",
    "                test_res += [ai[bi].tolist()]\n",
    "            test_ndcg = np.average([ndcg_at_k(resi, len(resi)) for resi in test_res])\n",
    "            print(test_ndcg)\n",
    "            del res\n",
    "    del train_data, valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = np.array(stats)\n",
    "plt.plot(stats[:,0])\n",
    "plt.plot(stats[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "gnn, classifier = model\n",
    "with torch.no_grad():\n",
    "    test_res = []\n",
    "    for _ in range(10):\n",
    "        _time = np.random.choice(list(test_papers.keys()))\n",
    "        node_feature, node_type, edge_time, edge_index, edge_type, field_ids, paper_ids, ylabel = pf_sample(np.random.randint(2 ** 32 - 1), test_papers, \\\n",
    "                                                       test_pairs, test_range, batch_size, test=True)\n",
    "        paper_rep = gnn.forward(node_feature.to(device), node_type.to(device), \\\n",
    "                      edge_time.to(device), edge_index.to(device), edge_type.to(device))[paper_ids]\n",
    "        res = classifier.forward(paper_rep)\n",
    "        for ai, bi in zip(ylabel, res.argsort(descending = True)):\n",
    "            test_res += [ai[bi].tolist()]\n",
    "    test_ndcg = [ndcg_at_k(resi, len(resi)) for resi in test_res]\n",
    "    print(np.average(test_ndcg), np.var(test_ndcg))\n",
    "    test_mrr = mean_reciprocal_rank(test_res)\n",
    "    print(np.average(test_mrr), np.var(test_mrr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = torch.load('./save/rgt_3.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.eval()\n",
    "gnn, classifier = best_model\n",
    "with torch.no_grad():\n",
    "    test_res = []\n",
    "    for _ in range(10):\n",
    "        _time = np.random.choice(list(test_papers.keys()))\n",
    "        node_feature, node_type, edge_time, edge_index, edge_type, field_ids, paper_ids, ylabel = pf_sample(np.random.randint(2 ** 32 - 1), test_papers, \\\n",
    "                                                       test_pairs, test_range, batch_size, test=True)\n",
    "        paper_rep = gnn.forward(node_feature.to(device), node_type.to(device), \\\n",
    "                      edge_time.to(device), edge_index.to(device), edge_type.to(device))[paper_ids]\n",
    "        res = classifier.forward(paper_rep)\n",
    "        for ai, bi in zip(ylabel, res.argsort(descending = True)):\n",
    "            test_res += [ai[bi].tolist()]\n",
    "    test_ndcg = [ndcg_at_k(resi, len(resi)) for resi in test_res]\n",
    "    print(np.average(test_ndcg), np.var(test_ndcg))\n",
    "    test_mrr = mean_reciprocal_rank(test_res)\n",
    "    print(np.average(test_mrr), np.var(test_mrr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without pre-train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = np.array(stats)\n",
    "plt.plot(stats[:,0])\n",
    "plt.plot(stats[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "gnn, classifier = model\n",
    "with torch.no_grad():\n",
    "    test_res = []\n",
    "    for _ in range(10):\n",
    "        _time = np.random.choice(list(test_papers.keys()))\n",
    "        node_feature, node_type, edge_time, edge_index, edge_type, field_ids, paper_ids, ylabel = pf_sample(np.random.randint(2 ** 32 - 1), test_papers, \\\n",
    "                                                       test_pairs, test_range, batch_size, test=True)\n",
    "        paper_rep = gnn.forward(node_feature.to(device), node_type.to(device), \\\n",
    "                      edge_time.to(device), edge_index.to(device), edge_type.to(device))[paper_ids]\n",
    "        res = classifier.forward(paper_rep)\n",
    "        for ai, bi in zip(ylabel, res.argsort(descending = True)):\n",
    "            test_res += [ai[bi].tolist()]\n",
    "    test_ndcg = [ndcg_at_k(resi, len(resi)) for resi in test_res]\n",
    "    print(np.average(test_ndcg), np.var(test_ndcg))\n",
    "    test_mrr = mean_reciprocal_rank(test_res)\n",
    "    print(np.average(test_mrr), np.var(test_mrr))\n",
    "    \n",
    "best_model = torch.load('./save/rgt_1.pt')\n",
    "\n",
    "best_model.eval()\n",
    "gnn, classifier = best_model\n",
    "with torch.no_grad():\n",
    "    test_res = []\n",
    "    for _ in range(10):\n",
    "        _time = np.random.choice(list(test_papers.keys()))\n",
    "        node_feature, node_type, edge_time, edge_index, edge_type, field_ids, paper_ids, ylabel = pf_sample(np.random.randint(2 ** 32 - 1), test_papers, \\\n",
    "                                                       test_pairs, test_range, batch_size, test=True)\n",
    "        paper_rep = gnn.forward(node_feature.to(device), node_type.to(device), \\\n",
    "                      edge_time.to(device), edge_index.to(device), edge_type.to(device))[paper_ids]\n",
    "        res = classifier.forward(paper_rep)\n",
    "        for ai, bi in zip(ylabel, res.argsort(descending = True)):\n",
    "            test_res += [ai[bi].tolist()]\n",
    "    test_ndcg = [ndcg_at_k(resi, len(resi)) for resi in test_res]\n",
    "    print(np.average(test_ndcg), np.var(test_ndcg))\n",
    "    test_mrr = mean_reciprocal_rank(test_res)\n",
    "    print(np.average(test_mrr), np.var(test_mrr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_fields = graph.node_feature['field'][graph.node_feature['field']['attr'] == 'L2'].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.node_feature['field'].iloc[[l2_fields[424]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.node_feature['field'].iloc[[l2_fields[637]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_fields[424], l2_fields[637]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers = []\n",
    "mxn = 0\n",
    "for f in l2_fields:\n",
    "    p = graph.edge_list['field']['paper']['PF_in_L2'][f]\n",
    "    if len(p) > 100 and len(p) < 10000:\n",
    "        papers += [p]\n",
    "len(papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "citation_matrix = np.zeros([len(papers), len(papers)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i1, j1 in enumerate(papers):\n",
    "    if i1 % 10 == 0:\n",
    "        print('%d / %d' % (i1, len(papers)))\n",
    "    for i2, j2 in enumerate(papers):\n",
    "        if i2 > i1: \n",
    "            continue\n",
    "        cnt = 0\n",
    "        for p1 in j1:\n",
    "            for p2 in graph.edge_list['paper']['paper']['PP_cite'][p1]:\n",
    "                if p2 in j2:\n",
    "                    cnt += 1\n",
    "        citation_matrix[i1][i2] = cnt / len(j1) / len(j2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "possible_ls = []\n",
    "th = 0.002\n",
    "for i in range(len(citation_matrix)):\n",
    "    for j in range(len(citation_matrix)):\n",
    "        if i >= j:\n",
    "            inter = citation_matrix[i][j]\n",
    "            left  = citation_matrix[i][i]\n",
    "            right = citation_matrix[j][j]\n",
    "#             if inter>th and left >= inter and right >= 0.7 * left and right <= left and right>=inter:\n",
    "            if inter>th and left >= inter and right>=inter:\n",
    "                if len(list(papers[i].keys()))>=2.5*len(list(papers[j].keys())):\n",
    "                    print(i,j, len(list(papers[i].keys())), len(list(papers[j].keys())))\n",
    "                    possible_ls.append([i,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_list_0 = list(papers[637].keys())\n",
    "paper_list_1 = list(papers[424].keys())\n",
    "print(len(paper_list_0), len(paper_list_1))\n",
    "_papers = paper_list_0 + paper_list_1\n",
    "paper_id = {j:i for i, j in enumerate(_papers)}\n",
    "paper_labels = {}\n",
    "for p in paper_list_0:\n",
    "    paper_labels[p] = 0\n",
    "for p in paper_list_1:\n",
    "    paper_labels[p] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_papers = paper_list_0 + paper_list_1\n",
    "paper_id = {j:i for i, j in enumerate(_papers)}\n",
    "paper_labels = {}\n",
    "for p in paper_list_0:\n",
    "    paper_labels[p] = 0\n",
    "for p in paper_list_1:\n",
    "    paper_labels[p] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = []\n",
    "degrees = defaultdict(lambda: 0)\n",
    "for pi in _papers:\n",
    "    for pj in  graph.edge_list['paper']['paper']['PP_cite'][pi]:\n",
    "        if pj in paper_id:\n",
    "            edges += [paper_id[pi], paper_id[pj]]\n",
    "            edges += [paper_id[pj], paper_id[pi]]\n",
    "            degrees[pi] += 1\n",
    "            degrees[pj] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "removes = {}\n",
    "for p in paper_list_0:\n",
    "    if degrees[p] <= 5 or degrees[p] > 60:\n",
    "        removes[p] = True\n",
    "for p in paper_list_1:\n",
    "    if degrees[p] <= 20 or degrees[p] > 60:\n",
    "        removes[p] = True\n",
    "_papers = [p for p in _papers if p not in removes]\n",
    "paper_id = {j:i for i, j in enumerate(_papers)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = []\n",
    "degrees = defaultdict(lambda: 0)\n",
    "rec = {}\n",
    "for pi in _papers:\n",
    "    for pj in graph.edge_list['paper']['paper']['PP_cite'][pi]:\n",
    "        if pj in paper_id:\n",
    "            if pi != pj:\n",
    "                e = [[paper_id[pi], paper_id[pj]]]\n",
    "                if \"%d_%d\" % (paper_id[pi], paper_id[pj]) not in rec:\n",
    "                    edges += [[paper_id[pi], paper_id[pj]]]\n",
    "                    edges += [[paper_id[pj], paper_id[pi]]]\n",
    "                    rec[\"%d_%d\" % (paper_id[pi], paper_id[pj])] = True\n",
    "                    rec[\"%d_%d\" % (paper_id[pj], paper_id[pi])] = True\n",
    "                    degrees[pi] += 1\n",
    "                    degrees[pj] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array(list(graph.node_feature['paper'].loc[_papers, 'emb']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "paper_list_0 = []\n",
    "paper_list_1 = []\n",
    "for p in _papers:\n",
    "    labels.append(paper_labels[p])\n",
    "    if paper_labels[p] == 0:\n",
    "        paper_list_0 += [p]\n",
    "    if paper_labels[p] == 1:\n",
    "        paper_list_1 += [p]\n",
    "print(len(paper_list_0), len(paper_list_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = defaultdict(lambda: 0)\n",
    "for l in labels:\n",
    "    cnt[l] += 1\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dill.dump((edges, features, labels), open('./data.pk', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(paper_list_0), len(paper_list_1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "for e in np.array(edges).reshape(-1, 2):\n",
    "    tr[labels[e[0]]][labels[e[1]]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr[0][0] / len(paper_list_0) / len(paper_list_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr[0][1] / len(paper_list_0) / len(paper_list_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr[1][1] / len(paper_list_1) / len(paper_list_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(paper_list_1) * len(paper_list_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
