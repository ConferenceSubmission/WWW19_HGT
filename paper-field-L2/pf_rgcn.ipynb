{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from utils import *\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/datadrive/data/'\n",
    "batch_size = 512\n",
    "batch_num  = 128\n",
    "epoch_num  = 1000\n",
    "samp_num   = 7\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "graph = dill.load(open(data_dir + 'graph.pk', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_range = {t: True for t in graph.times if t != None and t <= 2015}\n",
    "valid_range = {t: True for t in graph.times if t != None and (t > 2015) & (t < 2018)}\n",
    "test_range  = {t: True for t in graph.times if t != None and t >= 2018}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pf_sample(seed, papers, pairs, t_range, batch_size, test = False):\n",
    "    np.random.seed(seed)\n",
    "    _time = np.random.choice(list(papers.keys()))\n",
    "    pids = np.array(papers[_time])[np.random.choice(len(papers[_time]), batch_size, replace = False)]\n",
    "    fids = []\n",
    "    edge = defaultdict(lambda: {})\n",
    "    for x_id, p_id in enumerate(pids):\n",
    "        f_ids = pairs[p_id]\n",
    "        for f_id in f_ids:\n",
    "            if f_id not in fids:\n",
    "                fids += [f_id]\n",
    "            edge[x_id][fids.index(f_id)] = True\n",
    "    pids = np.stack([pids, np.repeat([_time], batch_size)]).T\n",
    "    fids = np.stack([fids, np.repeat([_time], len(fids))]).T\n",
    " \n",
    "    feature, times, edge_list = sample_subgraph(graph, t_range, \\\n",
    "                inp = {'paper': pids, 'field': fids}, sampled_depth = 4, sampled_number = 128)\n",
    "\n",
    "    el = []\n",
    "    for i in edge_list['paper']['field']['rev_PF_in']:\n",
    "        if i[0] in edge and i[1] in edge[i[0]]:\n",
    "            continue\n",
    "        el += [i]\n",
    "    edge_list['paper']['field']['rev_PF_in'] = el\n",
    "\n",
    "    el = []\n",
    "    for i in edge_list['field']['paper']['PF_in']:\n",
    "        if i[1] in edge and i[0] in edge[i[1]]:\n",
    "            continue\n",
    "        el += [i]\n",
    "    edge_list['field']['paper']['PF_in'] = el\n",
    "    \n",
    "    \n",
    "    node_feature, node_type, edge_time, edge_index, edge_type, node_dict, edge_dict = \\\n",
    "            to_torch(feature, times, edge_list)\n",
    "    '''\n",
    "        Trace the paper_id and field_id by its own index plus the type start index\n",
    "    '''\n",
    "    paper_ids = np.arange(len(pids)) + node_dict['paper'][0]\n",
    "    field_ids = np.arange(len(fids)) + node_dict['field'][0]\n",
    "    ylabel = torch.zeros(batch_size, len(ids))\n",
    "    for x_id, p_id in enumerate(pids[:,0]):\n",
    "        for f_id in pairs[p_id]:\n",
    "            ylabel[x_id][list(ids).index(f_id)] = 1\n",
    "    ylabel /= ylabel.sum(axis=1).view(-1, 1)\n",
    "    return node_feature, node_type, edge_time, edge_index, edge_type, field_ids, paper_ids, ylabel\n",
    "    \n",
    "def prepare_data(pool, process_ids):\n",
    "    jobs = []\n",
    "    for process_id in process_ids[:-1]:\n",
    "        p = pool.apply_async(pf_sample, args=(np.random.randint(2**32 - 1), train_papers, \\\n",
    "                                               train_pairs, train_range, batch_size))\n",
    "        jobs.append(p)\n",
    "    p = pool.apply_async(pf_sample, args=(np.random.randint(2**32 - 1), valid_papers, \\\n",
    "                                           valid_pairs, valid_range, batch_size))\n",
    "    jobs.append(p)\n",
    "    return jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RGCNConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels, num_relations, num_bases, device, **kwargs):\n",
    "        super(RGCNConv, self).__init__(aggr='add', **kwargs)\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.num_relations = num_relations\n",
    "        self.num_bases = num_bases\n",
    "        self.device = device\n",
    "        \n",
    "        self.basis = nn.Parameter(torch.Tensor(num_bases, in_channels, out_channels))\n",
    "        self.att   = nn.Parameter(torch.Tensor(num_relations, num_bases))\n",
    "        self.root  = nn.Linear(in_channels, out_channels)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        size = self.num_bases * self.in_channels\n",
    "        uniform(size, self.basis)\n",
    "        uniform(size, self.att)\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index, edge_type):\n",
    "        \"\"\"\"\"\"\n",
    "        return self.propagate(edge_index, x=x, edge_type=edge_type)\n",
    "\n",
    "\n",
    "    def message(self, x_j, edge_index_j, edge_type, edge_norm):\n",
    "        ws = torch.matmul(self.att, self.basis.view(self.num_bases, -1))\n",
    "        ws = ws.view(self.num_relations, self.in_channels, self.out_channels)\n",
    "        data_size = edge_index_j.size(0)\n",
    "        res = torch.zeros(data_size, self.out_channels).to(self.device)\n",
    "        \n",
    "        for r_id in range(self.num_relations):\n",
    "            w   = ws[r_id]\n",
    "            idx = (edge_type == r_id)\n",
    "            if idx.sum() == 0:\n",
    "                continue\n",
    "            batch_x_j = x_j[idx]\n",
    "            res[idx] = torch.mm(batch_x_j, w).squeeze(-2)\n",
    "        return res\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        return aggr_out\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}({}, {}, num_relations={})'.format(\n",
    "            self.__class__.__name__, self.in_channels, self.out_channels,\n",
    "            self.num_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(nn.Module):\n",
    "    def __init__(self, n_hid, n_layers, num_relations, device, dropout = 0.5):\n",
    "        super(GNN, self).__init__()\n",
    "        self.gcs = nn.ModuleList()\n",
    "        self.n_hid = n_hid\n",
    "        self.adapt = nn.Linear(n_hid, n_hid // 2)\n",
    "        self.drop  = nn.Dropout(dropout)\n",
    "        for l in range(n_layers):\n",
    "            self.gcs.append(RGCNConv(n_hid // 2, n_hid // 2, num_relations, int(math.sqrt(n_hid)), device))\n",
    "    def set_device(self, device):\n",
    "        self.device = device\n",
    "        for gc in self.gcs:\n",
    "            gc.device = device\n",
    "    def forward(self, node_feature, edge_index, edge_type):\n",
    "        meta_xs = self.drop(F.elu(self.adapt(node_feature)))\n",
    "        for gc in self.gcs:\n",
    "            meta_xs = self.drop(gc(meta_xs, edge_index, edge_type))\n",
    "        return meta_xs\n",
    "    def __repr__(self):\n",
    "        return '{}(n_hid={}, n_layers={})'.format(\n",
    "            self.__class__.__name__, self.n_hid, len(self.gcs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Paper-Field\n",
    "'''\n",
    "field_dict = dill.load(open(data_dir + 'field_dict.pk', 'rb'))\n",
    "ids = np.array([graph.node_forward['field'][k] for k in field_dict if field_dict[k][0] == 'L1'])\n",
    "\n",
    "paper_ser = {}\n",
    "\n",
    "train_pairs = {}\n",
    "valid_pairs = {}\n",
    "test_pairs  = {}\n",
    "\n",
    "train_papers = {_time: {} for _time in train_range}\n",
    "valid_papers = {_time: {} for _time in valid_range}\n",
    "test_papers  = {_time: {} for _time in test_range}\n",
    "\n",
    "for f_id in ids:\n",
    "    for p_id in graph.edge_list['field']['paper']['PF_in'][f_id]:\n",
    "        _time = graph.edge_list['field']['paper']['PF_in'][f_id][p_id]\n",
    "        if _time in train_range:\n",
    "            if p_id not in train_pairs:\n",
    "                train_pairs[p_id] = []\n",
    "            train_pairs[p_id] += [f_id]\n",
    "            train_papers[_time][p_id] = True\n",
    "        elif _time in valid_range:\n",
    "            if p_id not in valid_pairs:\n",
    "                valid_pairs[p_id] = []\n",
    "            valid_pairs[p_id] += [f_id]\n",
    "            valid_papers[_time][p_id] = True\n",
    "        else:\n",
    "            if p_id not in test_pairs:\n",
    "                test_pairs[p_id] = []\n",
    "            test_pairs[p_id] += [f_id]\n",
    "            test_papers[_time][p_id] = True\n",
    "for _time in list(train_papers.keys()):\n",
    "    if len(train_papers[_time]) < batch_size:\n",
    "        train_papers.pop(_time)\n",
    "    else:\n",
    "        train_papers[_time] = np.array(list(train_papers[_time].keys()))\n",
    "for _time in list(valid_papers.keys()):\n",
    "    if len(valid_papers[_time]) < batch_size:\n",
    "        valid_papers.pop(_time)\n",
    "    else:\n",
    "        valid_papers[_time] = np.array(list(valid_papers[_time].keys()))\n",
    "for _time in list(test_papers.keys()):\n",
    "    if len(test_papers[_time]) < batch_size:\n",
    "        test_papers.pop(_time)\n",
    "    else:\n",
    "        test_papers[_time] = np.array(list(test_papers[_time].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn = GNN(400, n_layers = 2, num_relations = len(graph.get_meta_graph()) + 1, device = device).to(device)\n",
    "classifier = Classifier(200, len(ids)).to(device)\n",
    "model = nn.Sequential(gnn, classifier)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 2000, eta_min=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Preparation: 89.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type GNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type RGCNConv. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 (75.6s)  LR: 0.00022 Train Loss: 3.91  Valid Loss: 4.48  Valid NDCG: 0.4821\n",
      "Data Preparation: 24.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type GNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type RGCNConv. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 (76.8s)  LR: 0.00030 Train Loss: 3.45  Valid Loss: 4.43  Valid NDCG: 0.5090\n",
      "Data Preparation: 28.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type GNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type RGCNConv. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 (72.1s)  LR: 0.00039 Train Loss: 3.22  Valid Loss: 3.48  Valid NDCG: 0.6111\n",
      "Data Preparation: 25.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type GNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type RGCNConv. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 (70.7s)  LR: 0.00048 Train Loss: 2.57  Valid Loss: 3.01  Valid NDCG: 0.6644\n",
      "Data Preparation: 26.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type GNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type RGCNConv. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 (80.1s)  LR: 0.00058 Train Loss: 2.20  Valid Loss: 2.20  Valid NDCG: 0.7179\n",
      "0.6570521721886435\n",
      "Data Preparation: 28.6s\n",
      "Epoch: 6 (73.5s)  LR: 0.00067 Train Loss: 2.32  Valid Loss: 2.50  Valid NDCG: 0.6770\n",
      "Data Preparation: 27.0s\n",
      "Epoch: 7 (71.4s)  LR: 0.00075 Train Loss: 2.04  Valid Loss: 2.31  Valid NDCG: 0.7089\n",
      "Data Preparation: 23.6s\n",
      "Epoch: 8 (69.6s)  LR: 0.00083 Train Loss: 1.81  Valid Loss: 2.56  Valid NDCG: 0.6810\n",
      "Data Preparation: 28.6s\n",
      "Epoch: 9 (69.8s)  LR: 0.00090 Train Loss: 2.33  Valid Loss: 2.27  Valid NDCG: 0.6927\n",
      "Data Preparation: 22.7s\n",
      "Epoch: 10 (68.1s)  LR: 0.00095 Train Loss: 1.77  Valid Loss: 2.39  Valid NDCG: 0.6758\n",
      "0.6504779980684388\n",
      "Data Preparation: 29.9s\n",
      "Epoch: 11 (70.7s)  LR: 0.00098 Train Loss: 1.79  Valid Loss: 2.20  Valid NDCG: 0.7055\n",
      "Data Preparation: 25.1s\n",
      "Epoch: 12 (68.5s)  LR: 0.00100 Train Loss: 1.70  Valid Loss: 2.40  Valid NDCG: 0.6902\n",
      "Data Preparation: 27.7s\n",
      "Epoch: 13 (69.1s)  LR: 0.00100 Train Loss: 1.64  Valid Loss: 2.52  Valid NDCG: 0.6595\n",
      "Data Preparation: 24.0s\n",
      "Epoch: 14 (76.4s)  LR: 0.00098 Train Loss: 1.66  Valid Loss: 2.37  Valid NDCG: 0.6858\n",
      "Data Preparation: 26.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type GNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type RGCNConv. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 (77.2s)  LR: 0.00095 Train Loss: 1.61  Valid Loss: 1.96  Valid NDCG: 0.7611\n",
      "0.6752642900499453\n",
      "Data Preparation: 28.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type GNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type RGCNConv. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 (73.0s)  LR: 0.00090 Train Loss: 1.65  Valid Loss: 1.96  Valid NDCG: 0.7742\n",
      "Data Preparation: 29.0s\n",
      "Epoch: 17 (73.0s)  LR: 0.00083 Train Loss: 1.81  Valid Loss: 2.34  Valid NDCG: 0.6806\n",
      "Data Preparation: 22.7s\n",
      "Epoch: 18 (73.9s)  LR: 0.00075 Train Loss: 1.64  Valid Loss: 2.09  Valid NDCG: 0.7336\n",
      "Data Preparation: 19.7s\n",
      "Epoch: 19 (75.3s)  LR: 0.00067 Train Loss: 1.56  Valid Loss: 2.15  Valid NDCG: 0.7219\n",
      "Data Preparation: 28.4s\n",
      "Epoch: 20 (75.5s)  LR: 0.00058 Train Loss: 1.59  Valid Loss: 2.36  Valid NDCG: 0.6839\n",
      "0.7375441750777545\n",
      "Data Preparation: 29.5s\n",
      "Epoch: 21 (71.4s)  LR: 0.00048 Train Loss: 1.50  Valid Loss: 2.13  Valid NDCG: 0.7257\n",
      "Data Preparation: 28.9s\n",
      "Epoch: 22 (74.2s)  LR: 0.00039 Train Loss: 1.49  Valid Loss: 2.13  Valid NDCG: 0.7422\n",
      "Data Preparation: 20.9s\n",
      "Epoch: 23 (74.9s)  LR: 0.00030 Train Loss: 1.42  Valid Loss: 2.14  Valid NDCG: 0.7222\n",
      "Data Preparation: 27.7s\n",
      "Epoch: 24 (69.4s)  LR: 0.00022 Train Loss: 1.45  Valid Loss: 1.92  Valid NDCG: 0.7507\n",
      "Data Preparation: 25.7s\n",
      "Epoch: 25 (71.6s)  LR: 0.00015 Train Loss: 1.51  Valid Loss: 2.26  Valid NDCG: 0.7114\n",
      "0.6566447336774175\n",
      "Data Preparation: 28.5s\n",
      "Epoch: 26 (74.3s)  LR: 0.00009 Train Loss: 1.48  Valid Loss: 1.96  Valid NDCG: 0.7612\n",
      "Data Preparation: 24.4s\n",
      "Epoch: 27 (69.6s)  LR: 0.00004 Train Loss: 1.40  Valid Loss: 1.98  Valid NDCG: 0.7539\n",
      "Data Preparation: 28.8s\n",
      "Epoch: 28 (75.8s)  LR: 0.00001 Train Loss: 1.41  Valid Loss: 2.26  Valid NDCG: 0.7148\n",
      "Data Preparation: 26.2s\n",
      "Epoch: 29 (77.6s)  LR: 0.00000 Train Loss: 1.48  Valid Loss: 2.00  Valid NDCG: 0.7474\n",
      "Data Preparation: 24.7s\n",
      "Epoch: 30 (80.2s)  LR: 0.00001 Train Loss: 1.51  Valid Loss: 2.09  Valid NDCG: 0.7249\n",
      "0.719797214105452\n",
      "Data Preparation: 28.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type GNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type RGCNConv. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31 (76.5s)  LR: 0.00003 Train Loss: 1.45  Valid Loss: 1.95  Valid NDCG: 0.7764\n",
      "Data Preparation: 27.8s\n",
      "Epoch: 32 (75.6s)  LR: 0.00007 Train Loss: 1.48  Valid Loss: 2.09  Valid NDCG: 0.7373\n",
      "Data Preparation: 25.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type GNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type RGCNConv. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33 (75.7s)  LR: 0.00012 Train Loss: 1.45  Valid Loss: 1.83  Valid NDCG: 0.7916\n",
      "Data Preparation: 26.7s\n",
      "Epoch: 34 (78.4s)  LR: 0.00019 Train Loss: 1.52  Valid Loss: 1.89  Valid NDCG: 0.7695\n",
      "Data Preparation: 25.0s\n",
      "Epoch: 35 (80.1s)  LR: 0.00027 Train Loss: 1.49  Valid Loss: 2.07  Valid NDCG: 0.7394\n",
      "0.7226416039316468\n",
      "Data Preparation: 30.2s\n",
      "Epoch: 36 (75.7s)  LR: 0.00036 Train Loss: 1.56  Valid Loss: 2.08  Valid NDCG: 0.7311\n",
      "Data Preparation: 28.8s\n",
      "Epoch: 37 (74.0s)  LR: 0.00045 Train Loss: 1.50  Valid Loss: 2.23  Valid NDCG: 0.7276\n",
      "Data Preparation: 23.9s\n",
      "Epoch: 38 (74.4s)  LR: 0.00055 Train Loss: 1.45  Valid Loss: 1.89  Valid NDCG: 0.7681\n",
      "Data Preparation: 31.9s\n",
      "Epoch: 39 (82.4s)  LR: 0.00064 Train Loss: 2.00  Valid Loss: 2.29  Valid NDCG: 0.7332\n",
      "Data Preparation: 26.3s\n",
      "Epoch: 40 (77.1s)  LR: 0.00073 Train Loss: 1.64  Valid Loss: 1.97  Valid NDCG: 0.7672\n",
      "0.6943810237312646\n",
      "Data Preparation: 30.2s\n",
      "Epoch: 41 (72.5s)  LR: 0.00081 Train Loss: 1.51  Valid Loss: 2.29  Valid NDCG: 0.7051\n",
      "Data Preparation: 25.9s\n",
      "Epoch: 42 (79.1s)  LR: 0.00088 Train Loss: 1.52  Valid Loss: 2.05  Valid NDCG: 0.7392\n",
      "Data Preparation: 24.6s\n",
      "Epoch: 43 (84.3s)  LR: 0.00093 Train Loss: 1.56  Valid Loss: 2.03  Valid NDCG: 0.7528\n",
      "Data Preparation: 24.0s\n",
      "Epoch: 44 (80.6s)  LR: 0.00097 Train Loss: 1.60  Valid Loss: 1.91  Valid NDCG: 0.7684\n",
      "Data Preparation: 26.7s\n",
      "Epoch: 45 (75.1s)  LR: 0.00099 Train Loss: 1.60  Valid Loss: 2.02  Valid NDCG: 0.7369\n",
      "0.7029859345875399\n",
      "Data Preparation: 33.8s\n",
      "Epoch: 46 (75.8s)  LR: 0.00100 Train Loss: 1.52  Valid Loss: 1.97  Valid NDCG: 0.7482\n",
      "Data Preparation: 23.0s\n",
      "Epoch: 47 (78.1s)  LR: 0.00099 Train Loss: 1.58  Valid Loss: 1.85  Valid NDCG: 0.7775\n",
      "Data Preparation: 29.4s\n",
      "Epoch: 48 (83.5s)  LR: 0.00096 Train Loss: 1.62  Valid Loss: 1.88  Valid NDCG: 0.7602\n",
      "Data Preparation: 22.0s\n",
      "Epoch: 49 (75.0s)  LR: 0.00091 Train Loss: 1.48  Valid Loss: 2.14  Valid NDCG: 0.7267\n",
      "Data Preparation: 23.0s\n",
      "Epoch: 50 (71.6s)  LR: 0.00085 Train Loss: 1.52  Valid Loss: 1.90  Valid NDCG: 0.7787\n",
      "0.6924386167009513\n",
      "Data Preparation: 31.0s\n",
      "Epoch: 51 (74.2s)  LR: 0.00078 Train Loss: 1.43  Valid Loss: 1.99  Valid NDCG: 0.7372\n",
      "Data Preparation: 31.5s\n",
      "Epoch: 52 (82.8s)  LR: 0.00070 Train Loss: 1.46  Valid Loss: 1.94  Valid NDCG: 0.7737\n",
      "Data Preparation: 25.5s\n",
      "Epoch: 53 (79.1s)  LR: 0.00061 Train Loss: 1.48  Valid Loss: 2.13  Valid NDCG: 0.7144\n",
      "Data Preparation: 26.3s\n",
      "Epoch: 54 (73.8s)  LR: 0.00052 Train Loss: 1.41  Valid Loss: 1.99  Valid NDCG: 0.7621\n",
      "Data Preparation: 27.1s\n",
      "Epoch: 55 (78.0s)  LR: 0.00042 Train Loss: 1.42  Valid Loss: 1.97  Valid NDCG: 0.7556\n",
      "0.7000633980941535\n",
      "Data Preparation: 32.2s\n",
      "Epoch: 56 (79.5s)  LR: 0.00033 Train Loss: 1.38  Valid Loss: 1.80  Valid NDCG: 0.7828\n",
      "Data Preparation: 28.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type GNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type RGCNConv. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 57 (80.3s)  LR: 0.00025 Train Loss: 1.36  Valid Loss: 1.67  Valid NDCG: 0.8020\n",
      "Data Preparation: 27.4s\n",
      "Epoch: 58 (78.5s)  LR: 0.00017 Train Loss: 1.41  Valid Loss: 1.88  Valid NDCG: 0.7716\n",
      "Data Preparation: 24.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type GNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type RGCNConv. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 59 (72.0s)  LR: 0.00010 Train Loss: 1.38  Valid Loss: 1.69  Valid NDCG: 0.8112\n",
      "Data Preparation: 27.2s\n",
      "Epoch: 60 (76.5s)  LR: 0.00005 Train Loss: 1.36  Valid Loss: 1.84  Valid NDCG: 0.7774\n",
      "0.7356713075389307\n",
      "Data Preparation: 29.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type GNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type RGCNConv. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 61 (83.3s)  LR: 0.00002 Train Loss: 1.42  Valid Loss: 1.59  Valid NDCG: 0.8221\n",
      "Data Preparation: 27.2s\n",
      "Epoch: 62 (76.9s)  LR: 0.00000 Train Loss: 1.39  Valid Loss: 1.79  Valid NDCG: 0.7957\n",
      "Data Preparation: 29.1s\n",
      "Epoch: 63 (74.0s)  LR: 0.00000 Train Loss: 1.39  Valid Loss: 1.95  Valid NDCG: 0.7691\n",
      "Data Preparation: 31.2s\n",
      "Epoch: 64 (77.2s)  LR: 0.00002 Train Loss: 1.40  Valid Loss: 1.77  Valid NDCG: 0.7889\n",
      "Data Preparation: 26.8s\n",
      "Epoch: 65 (79.3s)  LR: 0.00005 Train Loss: 1.35  Valid Loss: 1.93  Valid NDCG: 0.7466\n",
      "0.6912328152873801\n",
      "Data Preparation: 28.5s\n",
      "Epoch: 66 (80.1s)  LR: 0.00010 Train Loss: 1.39  Valid Loss: 1.87  Valid NDCG: 0.7742\n",
      "Data Preparation: 30.8s\n",
      "Epoch: 67 (78.3s)  LR: 0.00017 Train Loss: 1.39  Valid Loss: 1.93  Valid NDCG: 0.7596\n",
      "Data Preparation: 25.8s\n",
      "Epoch: 68 (71.4s)  LR: 0.00025 Train Loss: 1.40  Valid Loss: 1.84  Valid NDCG: 0.7715\n",
      "Data Preparation: 31.3s\n",
      "Epoch: 69 (78.1s)  LR: 0.00033 Train Loss: 1.41  Valid Loss: 1.81  Valid NDCG: 0.7939\n",
      "Data Preparation: 23.6s\n",
      "Epoch: 70 (81.2s)  LR: 0.00042 Train Loss: 1.44  Valid Loss: 1.94  Valid NDCG: 0.7556\n",
      "0.7567183987024008\n",
      "Data Preparation: 31.0s\n",
      "Epoch: 71 (81.3s)  LR: 0.00052 Train Loss: 1.44  Valid Loss: 1.92  Valid NDCG: 0.7711\n",
      "Data Preparation: 26.7s\n",
      "Epoch: 72 (78.3s)  LR: 0.00061 Train Loss: 1.48  Valid Loss: 1.95  Valid NDCG: 0.7611\n",
      "Data Preparation: 25.7s\n",
      "Epoch: 73 (71.3s)  LR: 0.00070 Train Loss: 1.38  Valid Loss: 1.80  Valid NDCG: 0.7879\n",
      "Data Preparation: 27.2s\n",
      "Epoch: 74 (79.3s)  LR: 0.00078 Train Loss: 33.30  Valid Loss: 3.51  Valid NDCG: 0.6153\n",
      "Data Preparation: 24.2s\n",
      "Epoch: 75 (79.5s)  LR: 0.00085 Train Loss: 2.52  Valid Loss: 2.26  Valid NDCG: 0.7130\n",
      "0.62472769976297\n",
      "Data Preparation: 31.1s\n",
      "Epoch: 76 (76.1s)  LR: 0.00091 Train Loss: 2.05  Valid Loss: 2.28  Valid NDCG: 0.7197\n",
      "Data Preparation: 27.1s\n",
      "Epoch: 77 (73.8s)  LR: 0.00096 Train Loss: 1.89  Valid Loss: 2.27  Valid NDCG: 0.7461\n",
      "Data Preparation: 24.0s\n",
      "Epoch: 78 (77.6s)  LR: 0.00099 Train Loss: 1.82  Valid Loss: 2.13  Valid NDCG: 0.7404\n",
      "Data Preparation: 25.2s\n",
      "Epoch: 79 (82.3s)  LR: 0.00100 Train Loss: 1.80  Valid Loss: 1.99  Valid NDCG: 0.7645\n",
      "Data Preparation: 22.9s\n",
      "Epoch: 80 (72.5s)  LR: 0.00099 Train Loss: 1.75  Valid Loss: 1.98  Valid NDCG: 0.7495\n",
      "0.6985716225508877\n",
      "Data Preparation: 30.1s\n",
      "Epoch: 81 (73.8s)  LR: 0.00097 Train Loss: 1.70  Valid Loss: 1.87  Valid NDCG: 0.7823\n",
      "Data Preparation: 29.4s\n",
      "Epoch: 82 (77.6s)  LR: 0.00093 Train Loss: 1.67  Valid Loss: 1.92  Valid NDCG: 0.7767\n",
      "Data Preparation: 25.4s\n",
      "Epoch: 83 (80.8s)  LR: 0.00088 Train Loss: 1.66  Valid Loss: 1.96  Valid NDCG: 0.7564\n",
      "Data Preparation: 31.1s\n",
      "Epoch: 84 (77.0s)  LR: 0.00081 Train Loss: 1.66  Valid Loss: 1.92  Valid NDCG: 0.7643\n",
      "Data Preparation: 29.2s\n",
      "Epoch: 85 (77.4s)  LR: 0.00073 Train Loss: 1.61  Valid Loss: 1.73  Valid NDCG: 0.7918\n",
      "0.7081386180362692\n",
      "Data Preparation: 29.7s\n",
      "Epoch: 86 (72.5s)  LR: 0.00064 Train Loss: 1.62  Valid Loss: 1.73  Valid NDCG: 0.8020\n",
      "Data Preparation: 25.7s\n",
      "Epoch: 87 (79.6s)  LR: 0.00055 Train Loss: 1.63  Valid Loss: 1.84  Valid NDCG: 0.7836\n",
      "Data Preparation: 27.4s\n",
      "Epoch: 88 (79.8s)  LR: 0.00045 Train Loss: 1.52  Valid Loss: 1.79  Valid NDCG: 0.7867\n",
      "Data Preparation: 29.2s\n",
      "Epoch: 89 (78.0s)  LR: 0.00036 Train Loss: 1.59  Valid Loss: 2.02  Valid NDCG: 0.7446\n",
      "Data Preparation: 25.8s\n",
      "Epoch: 90 (72.7s)  LR: 0.00027 Train Loss: 1.54  Valid Loss: 2.04  Valid NDCG: 0.7280\n",
      "0.7189619922997372\n",
      "Data Preparation: 31.9s\n",
      "Epoch: 91 (80.1s)  LR: 0.00019 Train Loss: 1.50  Valid Loss: 1.74  Valid NDCG: 0.7905\n",
      "Data Preparation: 27.3s\n",
      "Epoch: 92 (77.9s)  LR: 0.00012 Train Loss: 1.52  Valid Loss: 1.90  Valid NDCG: 0.7589\n",
      "Data Preparation: 24.5s\n",
      "Epoch: 93 (74.0s)  LR: 0.00007 Train Loss: 1.48  Valid Loss: 1.68  Valid NDCG: 0.7928\n",
      "Data Preparation: 29.8s\n",
      "Epoch: 94 (72.4s)  LR: 0.00003 Train Loss: 1.47  Valid Loss: 1.81  Valid NDCG: 0.7837\n",
      "Data Preparation: 26.0s\n",
      "Epoch: 95 (78.5s)  LR: 0.00001 Train Loss: 1.57  Valid Loss: 1.84  Valid NDCG: 0.7844\n",
      "0.6922166918387361\n",
      "Data Preparation: 29.1s\n",
      "Epoch: 96 (77.6s)  LR: 0.00000 Train Loss: 1.50  Valid Loss: 1.68  Valid NDCG: 0.7955\n",
      "Data Preparation: 28.4s\n",
      "Epoch: 97 (80.3s)  LR: 0.00001 Train Loss: 1.54  Valid Loss: 1.80  Valid NDCG: 0.7884\n",
      "Data Preparation: 25.9s\n",
      "Epoch: 98 (73.9s)  LR: 0.00004 Train Loss: 1.46  Valid Loss: 1.75  Valid NDCG: 0.7856\n",
      "Data Preparation: 28.3s\n",
      "Epoch: 99 (73.4s)  LR: 0.00009 Train Loss: 1.51  Valid Loss: 1.78  Valid NDCG: 0.7824\n",
      "Data Preparation: 25.5s\n",
      "Epoch: 100 (82.1s)  LR: 0.00015 Train Loss: 1.48  Valid Loss: 1.84  Valid NDCG: 0.7656\n",
      "0.6927719081675845\n",
      "Data Preparation: 28.6s\n",
      "Epoch: 101 (77.8s)  LR: 0.00022 Train Loss: 1.54  Valid Loss: 1.97  Valid NDCG: 0.7603\n",
      "Data Preparation: 30.3s\n",
      "Epoch: 102 (78.0s)  LR: 0.00030 Train Loss: 1.54  Valid Loss: 1.92  Valid NDCG: 0.7530\n",
      "Data Preparation: 27.1s\n",
      "Epoch: 103 (73.2s)  LR: 0.00039 Train Loss: 1.52  Valid Loss: 1.57  Valid NDCG: 0.8164\n",
      "Data Preparation: 28.0s\n",
      "Epoch: 104 (77.9s)  LR: 0.00048 Train Loss: 1.54  Valid Loss: 2.01  Valid NDCG: 0.7538\n",
      "Data Preparation: 28.2s\n",
      "Epoch: 105 (84.5s)  LR: 0.00058 Train Loss: 1.58  Valid Loss: 1.79  Valid NDCG: 0.7837\n",
      "0.7101061603087444\n",
      "Data Preparation: 30.7s\n",
      "Epoch: 106 (77.2s)  LR: 0.00067 Train Loss: 1.56  Valid Loss: 1.64  Valid NDCG: 0.7966\n",
      "Data Preparation: 27.8s\n",
      "Epoch: 107 (72.8s)  LR: 0.00075 Train Loss: 1.49  Valid Loss: 1.85  Valid NDCG: 0.7803\n",
      "Data Preparation: 29.0s\n",
      "Epoch: 108 (79.8s)  LR: 0.00083 Train Loss: 1.55  Valid Loss: 1.74  Valid NDCG: 0.7899\n",
      "Data Preparation: 23.8s\n",
      "Epoch: 109 (82.5s)  LR: 0.00090 Train Loss: 1.53  Valid Loss: 1.68  Valid NDCG: 0.7880\n",
      "Data Preparation: 24.3s\n",
      "Epoch: 110 (80.1s)  LR: 0.00095 Train Loss: 28.80  Valid Loss: 16.72  Valid NDCG: 0.5050\n",
      "0.4423734605192091\n",
      "Data Preparation: 30.5s\n",
      "Epoch: 111 (76.0s)  LR: 0.00098 Train Loss: 16.46  Valid Loss: 2.01  Valid NDCG: 0.7572\n",
      "Data Preparation: 29.0s\n",
      "Epoch: 112 (74.7s)  LR: 0.00100 Train Loss: 2.01  Valid Loss: 1.96  Valid NDCG: 0.7747\n",
      "Data Preparation: 25.5s\n",
      "Epoch: 113 (81.6s)  LR: 0.00100 Train Loss: 1.91  Valid Loss: 2.24  Valid NDCG: 0.7388\n",
      "Data Preparation: 28.7s\n",
      "Epoch: 114 (84.3s)  LR: 0.00098 Train Loss: 1.84  Valid Loss: 2.27  Valid NDCG: 0.7246\n",
      "Data Preparation: 20.1s\n",
      "Epoch: 115 (79.0s)  LR: 0.00095 Train Loss: 1.73  Valid Loss: 2.10  Valid NDCG: 0.7586\n",
      "0.7064566698195904\n",
      "Data Preparation: 31.0s\n",
      "Epoch: 116 (76.7s)  LR: 0.00090 Train Loss: 1.70  Valid Loss: 2.01  Valid NDCG: 0.7677\n",
      "Data Preparation: 24.6s\n",
      "Epoch: 117 (75.4s)  LR: 0.00083 Train Loss: 1.64  Valid Loss: 1.87  Valid NDCG: 0.7675\n",
      "Data Preparation: 24.5s\n",
      "Epoch: 118 (82.0s)  LR: 0.00075 Train Loss: 1.64  Valid Loss: 1.93  Valid NDCG: 0.7680\n",
      "Data Preparation: 21.6s\n",
      "Epoch: 119 (71.6s)  LR: 0.00067 Train Loss: 1.58  Valid Loss: 2.06  Valid NDCG: 0.7383\n",
      "Data Preparation: 28.7s\n",
      "Epoch: 120 (73.8s)  LR: 0.00058 Train Loss: 1.60  Valid Loss: 1.95  Valid NDCG: 0.7646\n",
      "0.760582397129238\n",
      "Data Preparation: 30.6s\n",
      "Epoch: 121 (78.2s)  LR: 0.00048 Train Loss: 1.57  Valid Loss: 1.93  Valid NDCG: 0.7648\n",
      "Data Preparation: 28.9s\n",
      "Epoch: 122 (80.8s)  LR: 0.00039 Train Loss: 1.62  Valid Loss: 1.96  Valid NDCG: 0.7742\n",
      "Data Preparation: 26.9s\n",
      "Epoch: 123 (79.8s)  LR: 0.00030 Train Loss: 1.54  Valid Loss: 1.81  Valid NDCG: 0.7751\n",
      "Data Preparation: 27.5s\n",
      "Epoch: 124 (78.0s)  LR: 0.00022 Train Loss: 1.60  Valid Loss: 1.85  Valid NDCG: 0.7751\n",
      "Data Preparation: 26.8s\n",
      "Epoch: 125 (72.4s)  LR: 0.00015 Train Loss: 1.52  Valid Loss: 1.74  Valid NDCG: 0.7924\n",
      "0.7461310983730476\n",
      "Data Preparation: 31.6s\n",
      "Epoch: 126 (80.1s)  LR: 0.00009 Train Loss: 1.52  Valid Loss: 1.81  Valid NDCG: 0.7839\n",
      "Data Preparation: 26.3s\n",
      "Epoch: 127 (79.3s)  LR: 0.00004 Train Loss: 1.51  Valid Loss: 1.85  Valid NDCG: 0.7686\n",
      "Data Preparation: 29.1s\n",
      "Epoch: 128 (78.6s)  LR: 0.00001 Train Loss: 1.51  Valid Loss: 1.99  Valid NDCG: 0.7539\n",
      "Data Preparation: 26.9s\n",
      "Epoch: 129 (76.3s)  LR: 0.00000 Train Loss: 1.58  Valid Loss: 1.95  Valid NDCG: 0.7466\n",
      "Data Preparation: 28.0s\n",
      "Epoch: 130 (75.9s)  LR: 0.00001 Train Loss: 1.56  Valid Loss: 1.79  Valid NDCG: 0.7838\n",
      "0.7339259028990701\n",
      "Data Preparation: 29.7s\n",
      "Epoch: 131 (77.2s)  LR: 0.00003 Train Loss: 1.58  Valid Loss: 1.73  Valid NDCG: 0.7875\n",
      "Data Preparation: 28.2s\n",
      "Epoch: 132 (75.4s)  LR: 0.00007 Train Loss: 1.59  Valid Loss: 1.94  Valid NDCG: 0.7727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Preparation: 29.1s\n",
      "Epoch: 133 (73.3s)  LR: 0.00012 Train Loss: 1.50  Valid Loss: 1.69  Valid NDCG: 0.7903\n",
      "Data Preparation: 24.5s\n",
      "Epoch: 134 (76.7s)  LR: 0.00019 Train Loss: 1.56  Valid Loss: 1.93  Valid NDCG: 0.7504\n",
      "Data Preparation: 29.5s\n",
      "Epoch: 135 (84.1s)  LR: 0.00027 Train Loss: 1.57  Valid Loss: 1.75  Valid NDCG: 0.7989\n",
      "0.6891143313247338\n",
      "Data Preparation: 28.8s\n",
      "Epoch: 136 (82.7s)  LR: 0.00036 Train Loss: 1.55  Valid Loss: 1.82  Valid NDCG: 0.7651\n",
      "Data Preparation: 23.7s\n",
      "Epoch: 137 (76.2s)  LR: 0.00045 Train Loss: 1.49  Valid Loss: 1.78  Valid NDCG: 0.7836\n",
      "Data Preparation: 27.6s\n",
      "Epoch: 138 (71.5s)  LR: 0.00055 Train Loss: 1.48  Valid Loss: 1.88  Valid NDCG: 0.7668\n",
      "Data Preparation: 27.8s\n",
      "Epoch: 139 (77.7s)  LR: 0.00064 Train Loss: 1.47  Valid Loss: 1.80  Valid NDCG: 0.7669\n",
      "Data Preparation: 26.1s\n",
      "Epoch: 140 (81.3s)  LR: 0.00073 Train Loss: 1.51  Valid Loss: 1.79  Valid NDCG: 0.7811\n",
      "0.6900471283739705\n",
      "Data Preparation: 29.5s\n",
      "Epoch: 141 (75.7s)  LR: 0.00081 Train Loss: 1.50  Valid Loss: 1.87  Valid NDCG: 0.7663\n",
      "Data Preparation: 28.9s\n",
      "Epoch: 142 (73.5s)  LR: 0.00088 Train Loss: 1.50  Valid Loss: 1.82  Valid NDCG: 0.7733\n",
      "Data Preparation: 30.1s\n",
      "Epoch: 143 (76.3s)  LR: 0.00093 Train Loss: 1.45  Valid Loss: 1.66  Valid NDCG: 0.8003\n",
      "Data Preparation: 30.9s\n",
      "Epoch: 144 (78.5s)  LR: 0.00097 Train Loss: 1.49  Valid Loss: 1.77  Valid NDCG: 0.7753\n",
      "Data Preparation: 27.6s\n",
      "Epoch: 145 (75.9s)  LR: 0.00099 Train Loss: 1.39  Valid Loss: 1.68  Valid NDCG: 0.7862\n",
      "0.7507605661446477\n",
      "Data Preparation: 30.0s\n",
      "Epoch: 146 (73.2s)  LR: 0.00100 Train Loss: 1.47  Valid Loss: 1.87  Valid NDCG: 0.7456\n",
      "Data Preparation: 27.3s\n",
      "Epoch: 147 (77.6s)  LR: 0.00099 Train Loss: 1.44  Valid Loss: 1.71  Valid NDCG: 0.7792\n",
      "Data Preparation: 26.3s\n",
      "Epoch: 148 (77.7s)  LR: 0.00096 Train Loss: 1.48  Valid Loss: 1.78  Valid NDCG: 0.7732\n",
      "Data Preparation: 27.9s\n",
      "Epoch: 149 (82.4s)  LR: 0.00091 Train Loss: 1.43  Valid Loss: 1.78  Valid NDCG: 0.7731\n",
      "Data Preparation: 23.1s\n",
      "Epoch: 150 (75.3s)  LR: 0.00085 Train Loss: 1.44  Valid Loss: 1.67  Valid NDCG: 0.7926\n",
      "0.7297565419325327\n",
      "Data Preparation: 31.4s\n",
      "Epoch: 151 (72.7s)  LR: 0.00078 Train Loss: 1.40  Valid Loss: 1.78  Valid NDCG: 0.7756\n",
      "Data Preparation: 27.3s\n",
      "Epoch: 152 (78.5s)  LR: 0.00070 Train Loss: 1.45  Valid Loss: 1.70  Valid NDCG: 0.7965\n",
      "Data Preparation: 26.6s\n",
      "Epoch: 153 (83.3s)  LR: 0.00061 Train Loss: 1.42  Valid Loss: 1.74  Valid NDCG: 0.7801\n",
      "Data Preparation: 28.9s\n",
      "Epoch: 154 (82.6s)  LR: 0.00052 Train Loss: 1.75  Valid Loss: 1.63  Valid NDCG: 0.8038\n",
      "Data Preparation: 22.8s\n",
      "Epoch: 155 (78.7s)  LR: 0.00042 Train Loss: 1.48  Valid Loss: 1.71  Valid NDCG: 0.7806\n",
      "0.7453543470417159\n",
      "Data Preparation: 30.6s\n",
      "Epoch: 156 (72.8s)  LR: 0.00033 Train Loss: 1.46  Valid Loss: 1.70  Valid NDCG: 0.7803\n",
      "Data Preparation: 26.9s\n",
      "Epoch: 157 (75.2s)  LR: 0.00025 Train Loss: 1.34  Valid Loss: 1.74  Valid NDCG: 0.7657\n",
      "Data Preparation: 32.8s\n",
      "Epoch: 158 (79.2s)  LR: 0.00017 Train Loss: 1.39  Valid Loss: 1.72  Valid NDCG: 0.7879\n",
      "Data Preparation: 27.1s\n",
      "Epoch: 159 (75.7s)  LR: 0.00010 Train Loss: 1.46  Valid Loss: 1.51  Valid NDCG: 0.8198\n",
      "Data Preparation: 28.1s\n",
      "Epoch: 160 (75.1s)  LR: 0.00005 Train Loss: 1.38  Valid Loss: 1.63  Valid NDCG: 0.7866\n",
      "0.7513815397882921\n",
      "Data Preparation: 30.3s\n",
      "Epoch: 161 (79.4s)  LR: 0.00002 Train Loss: 1.39  Valid Loss: 1.61  Valid NDCG: 0.8025\n",
      "Data Preparation: 24.7s\n",
      "Epoch: 162 (82.4s)  LR: 0.00000 Train Loss: 1.37  Valid Loss: 1.66  Valid NDCG: 0.7943\n",
      "Data Preparation: 24.3s\n",
      "Epoch: 163 (74.5s)  LR: 0.00000 Train Loss: 1.38  Valid Loss: 1.67  Valid NDCG: 0.7920\n",
      "Data Preparation: 27.6s\n",
      "Epoch: 164 (70.9s)  LR: 0.00002 Train Loss: 1.41  Valid Loss: 1.73  Valid NDCG: 0.7868\n",
      "Data Preparation: 29.9s\n",
      "Epoch: 165 (77.0s)  LR: 0.00005 Train Loss: 1.43  Valid Loss: 1.59  Valid NDCG: 0.8060\n",
      "0.7825274667835529\n",
      "Data Preparation: 30.7s\n",
      "Epoch: 166 (85.0s)  LR: 0.00010 Train Loss: 1.39  Valid Loss: 1.53  Valid NDCG: 0.8156\n",
      "Data Preparation: 28.8s\n",
      "Epoch: 167 (78.8s)  LR: 0.00017 Train Loss: 1.30  Valid Loss: 1.67  Valid NDCG: 0.7857\n",
      "Data Preparation: 27.8s\n",
      "Epoch: 168 (77.2s)  LR: 0.00025 Train Loss: 1.35  Valid Loss: 1.50  Valid NDCG: 0.8155\n",
      "Data Preparation: 25.4s\n",
      "Epoch: 169 (75.3s)  LR: 0.00033 Train Loss: 1.39  Valid Loss: 1.58  Valid NDCG: 0.7941\n",
      "Data Preparation: 30.2s\n",
      "Epoch: 170 (78.1s)  LR: 0.00042 Train Loss: 1.35  Valid Loss: 1.72  Valid NDCG: 0.7798\n",
      "0.7175715717549647\n",
      "Data Preparation: 29.4s\n",
      "Epoch: 171 (76.3s)  LR: 0.00052 Train Loss: 1.40  Valid Loss: 1.53  Valid NDCG: 0.8098\n",
      "Data Preparation: 30.9s\n",
      "Epoch: 172 (76.5s)  LR: 0.00061 Train Loss: 1.48  Valid Loss: 1.70  Valid NDCG: 0.7883\n",
      "Data Preparation: 24.8s\n",
      "Epoch: 173 (77.9s)  LR: 0.00070 Train Loss: 1.42  Valid Loss: 1.77  Valid NDCG: 0.7758\n",
      "Data Preparation: 25.8s\n",
      "Epoch: 174 (79.9s)  LR: 0.00078 Train Loss: 1.44  Valid Loss: 1.73  Valid NDCG: 0.7712\n",
      "Data Preparation: 25.1s\n",
      "Epoch: 175 (82.7s)  LR: 0.00085 Train Loss: 1.40  Valid Loss: 1.71  Valid NDCG: 0.7839\n",
      "0.7178462782987103\n",
      "Data Preparation: 29.2s\n",
      "Epoch: 176 (77.6s)  LR: 0.00091 Train Loss: 1.40  Valid Loss: 1.58  Valid NDCG: 0.8057\n",
      "Data Preparation: 29.2s\n",
      "Epoch: 177 (70.8s)  LR: 0.00096 Train Loss: 1.41  Valid Loss: 1.63  Valid NDCG: 0.7895\n",
      "Data Preparation: 29.0s\n",
      "Epoch: 178 (75.6s)  LR: 0.00099 Train Loss: 1.44  Valid Loss: 1.72  Valid NDCG: 0.7768\n",
      "Data Preparation: 29.5s\n",
      "Epoch: 179 (81.0s)  LR: 0.00100 Train Loss: 1.52  Valid Loss: 1.60  Valid NDCG: 0.8025\n",
      "Data Preparation: 23.9s\n",
      "Epoch: 180 (79.7s)  LR: 0.00099 Train Loss: 1.42  Valid Loss: 1.85  Valid NDCG: 0.7475\n",
      "0.7346302836876564\n",
      "Data Preparation: 30.6s\n",
      "Epoch: 181 (76.6s)  LR: 0.00097 Train Loss: 1.45  Valid Loss: 1.68  Valid NDCG: 0.7838\n",
      "Data Preparation: 26.5s\n",
      "Epoch: 182 (72.6s)  LR: 0.00093 Train Loss: 1.43  Valid Loss: 1.65  Valid NDCG: 0.7827\n",
      "Data Preparation: 28.8s\n",
      "Epoch: 183 (78.8s)  LR: 0.00088 Train Loss: 1.43  Valid Loss: 1.68  Valid NDCG: 0.7811\n",
      "Data Preparation: 26.7s\n",
      "Epoch: 184 (81.1s)  LR: 0.00081 Train Loss: 1.41  Valid Loss: 1.53  Valid NDCG: 0.8136\n",
      "Data Preparation: 28.0s\n",
      "Epoch: 185 (76.9s)  LR: 0.00073 Train Loss: 1.35  Valid Loss: 1.55  Valid NDCG: 0.8061\n",
      "0.7747843728462727\n",
      "Data Preparation: 30.1s\n",
      "Epoch: 186 (74.0s)  LR: 0.00064 Train Loss: 1.53  Valid Loss: 1.68  Valid NDCG: 0.7839\n",
      "Data Preparation: 26.8s\n",
      "Epoch: 187 (80.8s)  LR: 0.00055 Train Loss: 1.42  Valid Loss: 1.77  Valid NDCG: 0.7583\n",
      "Data Preparation: 25.2s\n",
      "Epoch: 188 (79.1s)  LR: 0.00045 Train Loss: 1.31  Valid Loss: 1.63  Valid NDCG: 0.8010\n",
      "Data Preparation: 29.7s\n",
      "Epoch: 189 (81.1s)  LR: 0.00036 Train Loss: 1.38  Valid Loss: 1.59  Valid NDCG: 0.7945\n",
      "Data Preparation: 26.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type GNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type RGCNConv. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 190 (70.0s)  LR: 0.00027 Train Loss: 1.36  Valid Loss: 1.46  Valid NDCG: 0.8308\n",
      "0.7327216455876273\n",
      "Data Preparation: 29.1s\n",
      "Epoch: 191 (70.2s)  LR: 0.00019 Train Loss: 1.26  Valid Loss: 1.59  Valid NDCG: 0.7983\n",
      "Data Preparation: 29.0s\n",
      "Epoch: 192 (68.8s)  LR: 0.00012 Train Loss: 1.28  Valid Loss: 1.51  Valid NDCG: 0.8122\n",
      "Data Preparation: 27.8s\n",
      "Epoch: 193 (70.7s)  LR: 0.00007 Train Loss: 1.28  Valid Loss: 1.49  Valid NDCG: 0.8115\n",
      "Data Preparation: 26.2s\n",
      "Epoch: 194 (70.1s)  LR: 0.00003 Train Loss: 1.38  Valid Loss: 1.68  Valid NDCG: 0.7831\n",
      "Data Preparation: 26.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type GNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type RGCNConv. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 195 (69.0s)  LR: 0.00001 Train Loss: 1.37  Valid Loss: 1.45  Valid NDCG: 0.8315\n",
      "0.7551308707431115\n",
      "Data Preparation: 31.9s\n",
      "Epoch: 196 (75.4s)  LR: 0.00000 Train Loss: 1.37  Valid Loss: 1.66  Valid NDCG: 0.7797\n",
      "Data Preparation: 20.4s\n",
      "Epoch: 197 (69.4s)  LR: 0.00001 Train Loss: 1.37  Valid Loss: 1.65  Valid NDCG: 0.7939\n",
      "Data Preparation: 29.5s\n",
      "Epoch: 198 (70.0s)  LR: 0.00004 Train Loss: 1.26  Valid Loss: 1.49  Valid NDCG: 0.8172\n",
      "Data Preparation: 29.7s\n",
      "Epoch: 199 (69.2s)  LR: 0.00009 Train Loss: 1.30  Valid Loss: 1.60  Valid NDCG: 0.7980\n",
      "Data Preparation: 25.0s\n",
      "Epoch: 200 (71.5s)  LR: 0.00015 Train Loss: 1.33  Valid Loss: 1.42  Valid NDCG: 0.8280\n",
      "0.7691542190576739\n",
      "Data Preparation: 29.5s\n",
      "Epoch: 201 (68.0s)  LR: 0.00022 Train Loss: 1.27  Valid Loss: 1.53  Valid NDCG: 0.8163\n",
      "Data Preparation: 28.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type GNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type RGCNConv. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 202 (68.3s)  LR: 0.00030 Train Loss: 1.34  Valid Loss: 1.50  Valid NDCG: 0.8316\n",
      "Data Preparation: 28.9s\n",
      "Epoch: 203 (71.3s)  LR: 0.00039 Train Loss: 1.35  Valid Loss: 1.59  Valid NDCG: 0.8108\n",
      "Data Preparation: 25.6s\n",
      "Epoch: 204 (71.7s)  LR: 0.00048 Train Loss: 1.37  Valid Loss: 1.70  Valid NDCG: 0.7794\n",
      "Data Preparation: 23.5s\n",
      "Epoch: 205 (69.1s)  LR: 0.00058 Train Loss: 1.37  Valid Loss: 1.57  Valid NDCG: 0.7980\n",
      "0.7731376533056254\n",
      "Data Preparation: 30.7s\n",
      "Epoch: 206 (72.2s)  LR: 0.00067 Train Loss: 1.40  Valid Loss: 1.55  Valid NDCG: 0.8012\n",
      "Data Preparation: 27.5s\n",
      "Epoch: 207 (71.4s)  LR: 0.00075 Train Loss: 1.47  Valid Loss: 1.58  Valid NDCG: 0.8028\n",
      "Data Preparation: 26.5s\n",
      "Epoch: 208 (69.5s)  LR: 0.00083 Train Loss: 1.47  Valid Loss: 1.54  Valid NDCG: 0.8039\n",
      "Data Preparation: 23.6s\n",
      "Epoch: 209 (70.2s)  LR: 0.00090 Train Loss: 1.38  Valid Loss: 1.71  Valid NDCG: 0.7668\n",
      "Data Preparation: 33.2s\n",
      "Epoch: 210 (71.7s)  LR: 0.00095 Train Loss: 1.46  Valid Loss: 1.62  Valid NDCG: 0.7898\n",
      "0.7374745163755059\n",
      "Data Preparation: 29.1s\n",
      "Epoch: 211 (71.4s)  LR: 0.00098 Train Loss: 1.38  Valid Loss: 1.68  Valid NDCG: 0.7711\n",
      "Data Preparation: 26.0s\n",
      "Epoch: 212 (73.8s)  LR: 0.00100 Train Loss: 1.42  Valid Loss: 1.69  Valid NDCG: 0.7774\n",
      "Data Preparation: 24.9s\n",
      "Epoch: 213 (73.0s)  LR: 0.00100 Train Loss: 1.43  Valid Loss: 1.79  Valid NDCG: 0.7503\n",
      "Data Preparation: 28.5s\n",
      "Epoch: 214 (69.2s)  LR: 0.00098 Train Loss: 1.34  Valid Loss: 1.56  Valid NDCG: 0.7999\n",
      "Data Preparation: 30.0s\n",
      "Epoch: 215 (73.1s)  LR: 0.00095 Train Loss: 1.46  Valid Loss: 1.57  Valid NDCG: 0.8138\n",
      "0.7326689551793075\n",
      "Data Preparation: 29.3s\n",
      "Epoch: 216 (69.1s)  LR: 0.00090 Train Loss: 1.46  Valid Loss: 1.70  Valid NDCG: 0.7834\n",
      "Data Preparation: 32.1s\n",
      "Epoch: 217 (70.4s)  LR: 0.00083 Train Loss: 8.03  Valid Loss: 1.81  Valid NDCG: 0.7769\n",
      "Data Preparation: 30.2s\n",
      "Epoch: 218 (71.5s)  LR: 0.00075 Train Loss: 1.85  Valid Loss: 1.73  Valid NDCG: 0.7945\n",
      "Data Preparation: 28.9s\n",
      "Epoch: 219 (68.3s)  LR: 0.00067 Train Loss: 1.58  Valid Loss: 1.67  Valid NDCG: 0.7826\n",
      "Data Preparation: 31.9s\n",
      "Epoch: 220 (68.8s)  LR: 0.00058 Train Loss: 1.57  Valid Loss: 1.66  Valid NDCG: 0.7915\n",
      "0.7281397312692207\n",
      "Data Preparation: 30.8s\n",
      "Epoch: 221 (70.1s)  LR: 0.00048 Train Loss: 1.41  Valid Loss: 1.67  Valid NDCG: 0.7794\n",
      "Data Preparation: 33.4s\n",
      "Epoch: 222 (72.2s)  LR: 0.00039 Train Loss: 1.40  Valid Loss: 1.54  Valid NDCG: 0.8187\n",
      "Data Preparation: 27.6s\n",
      "Epoch: 223 (74.7s)  LR: 0.00030 Train Loss: 1.45  Valid Loss: 1.62  Valid NDCG: 0.7992\n",
      "Data Preparation: 24.2s\n",
      "Epoch: 224 (71.9s)  LR: 0.00022 Train Loss: 1.38  Valid Loss: 1.64  Valid NDCG: 0.7848\n",
      "Data Preparation: 23.6s\n",
      "Epoch: 225 (72.0s)  LR: 0.00015 Train Loss: 1.41  Valid Loss: 1.62  Valid NDCG: 0.7960\n",
      "0.7600620786897881\n",
      "Data Preparation: 29.4s\n",
      "Epoch: 226 (69.2s)  LR: 0.00009 Train Loss: 1.38  Valid Loss: 1.48  Valid NDCG: 0.8160\n",
      "Data Preparation: 29.7s\n",
      "Epoch: 227 (71.9s)  LR: 0.00004 Train Loss: 1.43  Valid Loss: 1.46  Valid NDCG: 0.8263\n",
      "Data Preparation: 28.3s\n",
      "Epoch: 228 (71.0s)  LR: 0.00001 Train Loss: 1.39  Valid Loss: 1.70  Valid NDCG: 0.7845\n",
      "Data Preparation: 28.0s\n",
      "Epoch: 229 (70.7s)  LR: 0.00000 Train Loss: 1.44  Valid Loss: 1.67  Valid NDCG: 0.7890\n",
      "Data Preparation: 32.7s\n",
      "Epoch: 230 (69.8s)  LR: 0.00001 Train Loss: 1.41  Valid Loss: 1.62  Valid NDCG: 0.7971\n",
      "0.7460200993121413\n",
      "Data Preparation: 28.9s\n",
      "Epoch: 231 (73.4s)  LR: 0.00003 Train Loss: 1.44  Valid Loss: 1.69  Valid NDCG: 0.7831\n",
      "Data Preparation: 22.4s\n",
      "Epoch: 232 (69.0s)  LR: 0.00007 Train Loss: 1.37  Valid Loss: 1.57  Valid NDCG: 0.8006\n",
      "Data Preparation: 28.1s\n",
      "Epoch: 233 (70.2s)  LR: 0.00012 Train Loss: 1.40  Valid Loss: 1.71  Valid NDCG: 0.7800\n",
      "Data Preparation: 27.3s\n",
      "Epoch: 234 (71.2s)  LR: 0.00019 Train Loss: 1.38  Valid Loss: 1.48  Valid NDCG: 0.8212\n",
      "Data Preparation: 26.8s\n",
      "Epoch: 235 (69.2s)  LR: 0.00027 Train Loss: 1.39  Valid Loss: 1.65  Valid NDCG: 0.7913\n",
      "0.7374862683737398\n",
      "Data Preparation: 29.9s\n",
      "Epoch: 236 (69.3s)  LR: 0.00036 Train Loss: 1.36  Valid Loss: 1.78  Valid NDCG: 0.7604\n",
      "Data Preparation: 28.3s\n",
      "Epoch: 237 (71.6s)  LR: 0.00045 Train Loss: 1.42  Valid Loss: 1.66  Valid NDCG: 0.7932\n",
      "Data Preparation: 29.0s\n",
      "Epoch: 238 (73.6s)  LR: 0.00055 Train Loss: 1.43  Valid Loss: 1.54  Valid NDCG: 0.8196\n",
      "Data Preparation: 24.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type GNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type RGCNConv. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 239 (67.0s)  LR: 0.00064 Train Loss: 1.33  Valid Loss: 1.30  Valid NDCG: 0.8467\n",
      "Data Preparation: 30.2s\n",
      "Epoch: 240 (76.7s)  LR: 0.00073 Train Loss: 1.42  Valid Loss: 1.53  Valid NDCG: 0.8038\n",
      "0.7879822776326272\n",
      "Data Preparation: 29.7s\n",
      "Epoch: 241 (71.9s)  LR: 0.00081 Train Loss: 1.41  Valid Loss: 1.54  Valid NDCG: 0.8024\n",
      "Data Preparation: 29.1s\n",
      "Epoch: 242 (73.3s)  LR: 0.00088 Train Loss: 1.41  Valid Loss: 1.74  Valid NDCG: 0.7724\n",
      "Data Preparation: 27.6s\n",
      "Epoch: 243 (71.1s)  LR: 0.00093 Train Loss: 1.37  Valid Loss: 1.56  Valid NDCG: 0.7985\n",
      "Data Preparation: 26.6s\n",
      "Epoch: 244 (70.6s)  LR: 0.00097 Train Loss: 1.34  Valid Loss: 1.59  Valid NDCG: 0.7936\n",
      "Data Preparation: 27.9s\n",
      "Epoch: 245 (75.7s)  LR: 0.00099 Train Loss: 1.45  Valid Loss: 1.71  Valid NDCG: 0.7705\n",
      "0.7270293278660179\n",
      "Data Preparation: 28.9s\n",
      "Epoch: 246 (72.6s)  LR: 0.00100 Train Loss: 1.40  Valid Loss: 1.69  Valid NDCG: 0.7762\n",
      "Data Preparation: 22.9s\n",
      "Epoch: 247 (69.5s)  LR: 0.00099 Train Loss: 1.38  Valid Loss: 1.50  Valid NDCG: 0.8024\n",
      "Data Preparation: 27.1s\n",
      "Epoch: 248 (72.2s)  LR: 0.00096 Train Loss: 10.43  Valid Loss: 1.67  Valid NDCG: 0.7821\n",
      "Data Preparation: 27.0s\n",
      "Epoch: 249 (72.5s)  LR: 0.00091 Train Loss: 2.09  Valid Loss: 1.77  Valid NDCG: 0.7654\n",
      "Data Preparation: 25.7s\n",
      "Epoch: 250 (70.4s)  LR: 0.00085 Train Loss: 1.71  Valid Loss: 1.67  Valid NDCG: 0.7700\n",
      "0.7670281567210235\n",
      "Data Preparation: 30.3s\n",
      "Epoch: 251 (72.6s)  LR: 0.00078 Train Loss: 1.56  Valid Loss: 1.55  Valid NDCG: 0.8055\n",
      "Data Preparation: 28.9s\n",
      "Epoch: 252 (71.7s)  LR: 0.00070 Train Loss: 1.60  Valid Loss: 1.55  Valid NDCG: 0.8040\n",
      "Data Preparation: 29.0s\n",
      "Epoch: 253 (69.6s)  LR: 0.00061 Train Loss: 1.54  Valid Loss: 1.51  Valid NDCG: 0.8174\n",
      "Data Preparation: 28.9s\n",
      "Epoch: 254 (72.5s)  LR: 0.00052 Train Loss: 1.48  Valid Loss: 1.61  Valid NDCG: 0.7894\n",
      "Data Preparation: 26.2s\n",
      "Epoch: 255 (70.4s)  LR: 0.00042 Train Loss: 1.49  Valid Loss: 1.62  Valid NDCG: 0.7994\n",
      "0.7412402901232497\n",
      "Data Preparation: 29.9s\n",
      "Epoch: 256 (70.5s)  LR: 0.00033 Train Loss: 1.45  Valid Loss: 1.51  Valid NDCG: 0.8129\n",
      "Data Preparation: 25.0s\n",
      "Epoch: 257 (71.1s)  LR: 0.00025 Train Loss: 1.40  Valid Loss: 1.53  Valid NDCG: 0.8028\n",
      "Data Preparation: 26.5s\n",
      "Epoch: 258 (71.0s)  LR: 0.00017 Train Loss: 1.44  Valid Loss: 1.57  Valid NDCG: 0.8041\n",
      "Data Preparation: 22.1s\n",
      "Epoch: 259 (68.2s)  LR: 0.00010 Train Loss: 1.38  Valid Loss: 1.58  Valid NDCG: 0.8019\n",
      "Data Preparation: 28.6s\n",
      "Epoch: 260 (73.2s)  LR: 0.00005 Train Loss: 1.46  Valid Loss: 1.52  Valid NDCG: 0.8116\n",
      "0.7229348785609584\n",
      "Data Preparation: 28.9s\n",
      "Epoch: 261 (73.2s)  LR: 0.00002 Train Loss: 1.43  Valid Loss: 1.64  Valid NDCG: 0.7887\n",
      "Data Preparation: 27.1s\n",
      "Epoch: 262 (69.1s)  LR: 0.00000 Train Loss: 1.46  Valid Loss: 1.60  Valid NDCG: 0.8123\n",
      "Data Preparation: 29.7s\n",
      "Epoch: 263 (73.0s)  LR: 0.00000 Train Loss: 1.42  Valid Loss: 1.46  Valid NDCG: 0.8275\n",
      "Data Preparation: 25.5s\n",
      "Epoch: 264 (70.0s)  LR: 0.00002 Train Loss: 1.46  Valid Loss: 1.39  Valid NDCG: 0.8316\n",
      "Data Preparation: 32.4s\n",
      "Epoch: 265 (73.6s)  LR: 0.00005 Train Loss: 1.42  Valid Loss: 1.60  Valid NDCG: 0.8009\n",
      "0.7882459284132204\n",
      "Data Preparation: 29.3s\n",
      "Epoch: 266 (72.7s)  LR: 0.00010 Train Loss: 1.37  Valid Loss: 1.63  Valid NDCG: 0.7964\n",
      "Data Preparation: 26.6s\n",
      "Epoch: 267 (75.4s)  LR: 0.00017 Train Loss: 1.47  Valid Loss: 1.56  Valid NDCG: 0.7955\n",
      "Data Preparation: 24.4s\n",
      "Epoch: 268 (70.4s)  LR: 0.00025 Train Loss: 1.37  Valid Loss: 1.58  Valid NDCG: 0.8039\n",
      "Data Preparation: 30.3s\n",
      "Epoch: 269 (69.6s)  LR: 0.00033 Train Loss: 1.42  Valid Loss: 1.57  Valid NDCG: 0.8062\n",
      "Data Preparation: 27.4s\n",
      "Epoch: 270 (71.5s)  LR: 0.00042 Train Loss: 1.38  Valid Loss: 1.65  Valid NDCG: 0.7855\n",
      "0.7513594241054655\n",
      "Data Preparation: 30.4s\n",
      "Epoch: 271 (70.5s)  LR: 0.00052 Train Loss: 1.37  Valid Loss: 1.50  Valid NDCG: 0.8163\n",
      "Data Preparation: 28.1s\n",
      "Epoch: 272 (74.4s)  LR: 0.00061 Train Loss: 1.38  Valid Loss: 1.48  Valid NDCG: 0.8197\n",
      "Data Preparation: 26.6s\n",
      "Epoch: 273 (71.4s)  LR: 0.00070 Train Loss: 1.37  Valid Loss: 1.39  Valid NDCG: 0.8372\n",
      "Data Preparation: 26.9s\n",
      "Epoch: 274 (71.6s)  LR: 0.00078 Train Loss: 1.38  Valid Loss: 1.55  Valid NDCG: 0.7951\n",
      "Data Preparation: 29.2s\n",
      "Epoch: 275 (71.8s)  LR: 0.00085 Train Loss: 1.34  Valid Loss: 1.65  Valid NDCG: 0.7804\n",
      "0.7572409825152541\n",
      "Data Preparation: 29.1s\n",
      "Epoch: 276 (72.3s)  LR: 0.00091 Train Loss: 1.41  Valid Loss: 1.38  Valid NDCG: 0.8278\n",
      "Data Preparation: 28.2s\n",
      "Epoch: 277 (72.2s)  LR: 0.00096 Train Loss: 1.41  Valid Loss: 1.62  Valid NDCG: 0.7934\n",
      "Data Preparation: 26.3s\n",
      "Epoch: 278 (70.7s)  LR: 0.00099 Train Loss: 1.36  Valid Loss: 1.75  Valid NDCG: 0.7543\n",
      "Data Preparation: 29.5s\n",
      "Epoch: 279 (70.7s)  LR: 0.00100 Train Loss: 2.97  Valid Loss: 1.67  Valid NDCG: 0.7806\n",
      "Data Preparation: 27.3s\n",
      "Epoch: 280 (69.9s)  LR: 0.00099 Train Loss: 8.90  Valid Loss: 1.79  Valid NDCG: 0.7757\n",
      "0.6986372142916855\n",
      "Data Preparation: 29.9s\n",
      "Epoch: 281 (73.7s)  LR: 0.00097 Train Loss: 1.75  Valid Loss: 1.48  Valid NDCG: 0.8245\n",
      "Data Preparation: 25.3s\n",
      "Epoch: 282 (75.3s)  LR: 0.00093 Train Loss: 1.58  Valid Loss: 1.66  Valid NDCG: 0.7898\n",
      "Data Preparation: 23.6s\n",
      "Epoch: 283 (73.1s)  LR: 0.00088 Train Loss: 1.55  Valid Loss: 1.57  Valid NDCG: 0.8033\n",
      "Data Preparation: 26.4s\n",
      "Epoch: 284 (71.9s)  LR: 0.00081 Train Loss: 1.47  Valid Loss: 1.57  Valid NDCG: 0.8083\n",
      "Data Preparation: 29.4s\n",
      "Epoch: 285 (72.3s)  LR: 0.00073 Train Loss: 1.44  Valid Loss: 1.51  Valid NDCG: 0.8225\n",
      "0.77964843652054\n",
      "Data Preparation: 29.4s\n",
      "Epoch: 286 (73.1s)  LR: 0.00064 Train Loss: 1.46  Valid Loss: 1.58  Valid NDCG: 0.7958\n",
      "Data Preparation: 28.6s\n",
      "Epoch: 287 (71.8s)  LR: 0.00055 Train Loss: 1.42  Valid Loss: 1.35  Valid NDCG: 0.8419\n",
      "Data Preparation: 27.6s\n",
      "Epoch: 288 (71.8s)  LR: 0.00045 Train Loss: 1.41  Valid Loss: 1.48  Valid NDCG: 0.8175\n",
      "Data Preparation: 30.2s\n",
      "Epoch: 289 (72.7s)  LR: 0.00036 Train Loss: 1.43  Valid Loss: 1.60  Valid NDCG: 0.7990\n",
      "Data Preparation: 27.1s\n",
      "Epoch: 290 (73.1s)  LR: 0.00027 Train Loss: 1.39  Valid Loss: 1.51  Valid NDCG: 0.8160\n",
      "0.7910502200177076\n",
      "Data Preparation: 29.6s\n",
      "Epoch: 291 (69.8s)  LR: 0.00019 Train Loss: 1.40  Valid Loss: 1.50  Valid NDCG: 0.8169\n",
      "Data Preparation: 26.1s\n",
      "Epoch: 292 (74.4s)  LR: 0.00012 Train Loss: 1.35  Valid Loss: 1.49  Valid NDCG: 0.8207\n",
      "Data Preparation: 26.3s\n",
      "Epoch: 293 (73.0s)  LR: 0.00007 Train Loss: 1.44  Valid Loss: 1.41  Valid NDCG: 0.8218\n",
      "Data Preparation: 26.0s\n",
      "Epoch: 294 (71.7s)  LR: 0.00003 Train Loss: 1.38  Valid Loss: 1.50  Valid NDCG: 0.8223\n",
      "Data Preparation: 28.7s\n",
      "Epoch: 295 (75.0s)  LR: 0.00001 Train Loss: 1.36  Valid Loss: 1.46  Valid NDCG: 0.8165\n",
      "0.7605396105075887\n",
      "Data Preparation: 29.2s\n",
      "Epoch: 296 (72.6s)  LR: 0.00000 Train Loss: 1.37  Valid Loss: 1.39  Valid NDCG: 0.8377\n",
      "Data Preparation: 28.3s\n",
      "Epoch: 297 (72.7s)  LR: 0.00001 Train Loss: 1.43  Valid Loss: 1.59  Valid NDCG: 0.7905\n",
      "Data Preparation: 23.1s\n",
      "Epoch: 298 (69.4s)  LR: 0.00004 Train Loss: 1.43  Valid Loss: 1.44  Valid NDCG: 0.8286\n",
      "Data Preparation: 28.1s\n",
      "Epoch: 299 (72.6s)  LR: 0.00009 Train Loss: 1.39  Valid Loss: 1.55  Valid NDCG: 0.7981\n",
      "Data Preparation: 26.3s\n",
      "Epoch: 300 (70.7s)  LR: 0.00015 Train Loss: 1.41  Valid Loss: 1.60  Valid NDCG: 0.8065\n",
      "0.768366895713916\n",
      "Data Preparation: 30.4s\n",
      "Epoch: 301 (70.7s)  LR: 0.00022 Train Loss: 1.41  Valid Loss: 1.64  Valid NDCG: 0.7870\n",
      "Data Preparation: 28.2s\n",
      "Epoch: 302 (71.1s)  LR: 0.00030 Train Loss: 1.34  Valid Loss: 1.54  Valid NDCG: 0.7984\n",
      "Data Preparation: 31.1s\n",
      "Epoch: 303 (71.9s)  LR: 0.00039 Train Loss: 1.41  Valid Loss: 1.61  Valid NDCG: 0.8103\n",
      "Data Preparation: 27.8s\n",
      "Epoch: 304 (74.3s)  LR: 0.00048 Train Loss: 1.38  Valid Loss: 1.66  Valid NDCG: 0.7758\n",
      "Data Preparation: 25.6s\n",
      "Epoch: 305 (74.0s)  LR: 0.00058 Train Loss: 1.40  Valid Loss: 1.53  Valid NDCG: 0.8127\n",
      "0.7637247568814849\n",
      "Data Preparation: 49.5s\n",
      "Epoch: 306 (74.3s)  LR: 0.00067 Train Loss: 1.43  Valid Loss: 1.58  Valid NDCG: 0.7919\n",
      "Data Preparation: 37.0s\n",
      "Epoch: 307 (72.8s)  LR: 0.00075 Train Loss: 1.42  Valid Loss: 1.51  Valid NDCG: 0.8097\n",
      "Data Preparation: 51.0s\n",
      "Epoch: 308 (74.9s)  LR: 0.00083 Train Loss: 1.40  Valid Loss: 1.63  Valid NDCG: 0.7917\n",
      "Data Preparation: 49.4s\n",
      "Epoch: 309 (73.1s)  LR: 0.00090 Train Loss: 1.33  Valid Loss: 1.43  Valid NDCG: 0.8164\n",
      "Data Preparation: 42.6s\n",
      "Epoch: 310 (72.9s)  LR: 0.00095 Train Loss: 1.31  Valid Loss: 1.59  Valid NDCG: 0.7961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.786277403588793\n",
      "Data Preparation: 51.1s\n",
      "Epoch: 311 (73.2s)  LR: 0.00098 Train Loss: 1.35  Valid Loss: 1.62  Valid NDCG: 0.7982\n",
      "Data Preparation: 51.0s\n",
      "Epoch: 312 (72.1s)  LR: 0.00100 Train Loss: 1.33  Valid Loss: 1.44  Valid NDCG: 0.8225\n",
      "Data Preparation: 48.6s\n",
      "Epoch: 313 (73.5s)  LR: 0.00100 Train Loss: 1.38  Valid Loss: 1.53  Valid NDCG: 0.8120\n",
      "Data Preparation: 46.8s\n",
      "Epoch: 314 (74.1s)  LR: 0.00098 Train Loss: 1.40  Valid Loss: 1.44  Valid NDCG: 0.8241\n",
      "Data Preparation: 47.5s\n",
      "Epoch: 315 (71.3s)  LR: 0.00095 Train Loss: 1.40  Valid Loss: 1.51  Valid NDCG: 0.8115\n",
      "0.7736641617166224\n",
      "Data Preparation: 55.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type GNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ziniu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type RGCNConv. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 316 (73.1s)  LR: 0.00090 Train Loss: 1.37  Valid Loss: 1.23  Valid NDCG: 0.8622\n",
      "Data Preparation: 49.6s\n",
      "Epoch: 317 (73.4s)  LR: 0.00083 Train Loss: 1.39  Valid Loss: 1.58  Valid NDCG: 0.7956\n",
      "Data Preparation: 50.3s\n",
      "Epoch: 318 (72.4s)  LR: 0.00075 Train Loss: 1.32  Valid Loss: 1.50  Valid NDCG: 0.8097\n",
      "Data Preparation: 50.0s\n",
      "Epoch: 319 (70.4s)  LR: 0.00067 Train Loss: 1.99  Valid Loss: 1.56  Valid NDCG: 0.8028\n",
      "Data Preparation: 51.0s\n",
      "Epoch: 320 (72.7s)  LR: 0.00058 Train Loss: 1.43  Valid Loss: 1.47  Valid NDCG: 0.8222\n",
      "0.7400516935548698\n",
      "Data Preparation: 52.7s\n",
      "Epoch: 321 (72.4s)  LR: 0.00048 Train Loss: 1.38  Valid Loss: 1.37  Valid NDCG: 0.8432\n",
      "Data Preparation: 50.8s\n",
      "Epoch: 322 (70.7s)  LR: 0.00039 Train Loss: 1.30  Valid Loss: 1.48  Valid NDCG: 0.8287\n",
      "Data Preparation: 55.7s\n",
      "Epoch: 323 (75.6s)  LR: 0.00030 Train Loss: 1.35  Valid Loss: 1.48  Valid NDCG: 0.8268\n",
      "Data Preparation: 50.2s\n",
      "Epoch: 324 (72.6s)  LR: 0.00022 Train Loss: 1.35  Valid Loss: 1.39  Valid NDCG: 0.8205\n",
      "Data Preparation: 49.7s\n",
      "Epoch: 325 (70.0s)  LR: 0.00015 Train Loss: 1.32  Valid Loss: 1.49  Valid NDCG: 0.8270\n",
      "0.8029620525847312\n",
      "Data Preparation: 49.4s\n",
      "Epoch: 326 (73.1s)  LR: 0.00009 Train Loss: 1.29  Valid Loss: 1.51  Valid NDCG: 0.8118\n",
      "Data Preparation: 51.9s\n",
      "Epoch: 327 (71.4s)  LR: 0.00004 Train Loss: 1.31  Valid Loss: 1.44  Valid NDCG: 0.8246\n",
      "Data Preparation: 48.5s\n",
      "Epoch: 328 (71.5s)  LR: 0.00001 Train Loss: 1.35  Valid Loss: 1.42  Valid NDCG: 0.8260\n",
      "Data Preparation: 51.7s\n",
      "Epoch: 329 (71.5s)  LR: 0.00000 Train Loss: 1.32  Valid Loss: 1.48  Valid NDCG: 0.8162\n",
      "Data Preparation: 51.6s\n",
      "Epoch: 330 (72.5s)  LR: 0.00001 Train Loss: 1.31  Valid Loss: 1.64  Valid NDCG: 0.7784\n",
      "0.7872988398263805\n",
      "Data Preparation: 52.2s\n",
      "Epoch: 331 (73.8s)  LR: 0.00003 Train Loss: 1.33  Valid Loss: 1.55  Valid NDCG: 0.7982\n",
      "Data Preparation: 47.9s\n",
      "Epoch: 332 (73.7s)  LR: 0.00007 Train Loss: 1.27  Valid Loss: 1.40  Valid NDCG: 0.8305\n",
      "Data Preparation: 52.3s\n",
      "Epoch: 333 (75.8s)  LR: 0.00012 Train Loss: 1.36  Valid Loss: 1.56  Valid NDCG: 0.8024\n",
      "Data Preparation: 48.9s\n",
      "Epoch: 334 (74.1s)  LR: 0.00019 Train Loss: 1.32  Valid Loss: 1.57  Valid NDCG: 0.7898\n",
      "Data Preparation: 47.1s\n",
      "Epoch: 335 (73.7s)  LR: 0.00027 Train Loss: 1.37  Valid Loss: 1.50  Valid NDCG: 0.8230\n",
      "0.7550026044318425\n",
      "Data Preparation: 50.5s\n",
      "Epoch: 336 (70.2s)  LR: 0.00036 Train Loss: 1.35  Valid Loss: 1.42  Valid NDCG: 0.8232\n",
      "Data Preparation: 55.8s\n",
      "Epoch: 337 (72.6s)  LR: 0.00045 Train Loss: 1.34  Valid Loss: 1.51  Valid NDCG: 0.8129\n",
      "Data Preparation: 47.8s\n",
      "Epoch: 338 (70.2s)  LR: 0.00055 Train Loss: 1.33  Valid Loss: 1.47  Valid NDCG: 0.8229\n",
      "Data Preparation: 48.3s\n",
      "Epoch: 339 (70.5s)  LR: 0.00064 Train Loss: 1.32  Valid Loss: 1.47  Valid NDCG: 0.8169\n",
      "Data Preparation: 49.6s\n",
      "Epoch: 340 (73.6s)  LR: 0.00073 Train Loss: 1.40  Valid Loss: 1.60  Valid NDCG: 0.7876\n",
      "0.743826822883726\n",
      "Data Preparation: 49.4s\n",
      "Epoch: 341 (72.6s)  LR: 0.00081 Train Loss: 1.34  Valid Loss: 1.50  Valid NDCG: 0.8023\n",
      "Data Preparation: 48.5s\n",
      "Epoch: 342 (70.9s)  LR: 0.00088 Train Loss: 1.66  Valid Loss: 1.75  Valid NDCG: 0.7560\n",
      "Data Preparation: 50.2s\n",
      "Epoch: 343 (70.3s)  LR: 0.00093 Train Loss: 6.47  Valid Loss: 1.59  Valid NDCG: 0.7950\n",
      "Data Preparation: 53.6s\n",
      "Epoch: 344 (70.5s)  LR: 0.00097 Train Loss: 1.60  Valid Loss: 1.47  Valid NDCG: 0.8217\n",
      "Data Preparation: 52.8s\n",
      "Epoch: 345 (77.1s)  LR: 0.00099 Train Loss: 1.54  Valid Loss: 1.57  Valid NDCG: 0.7977\n",
      "0.7543288430549966\n",
      "Data Preparation: 46.1s\n",
      "Epoch: 346 (71.4s)  LR: 0.00100 Train Loss: 1.43  Valid Loss: 1.49  Valid NDCG: 0.8104\n",
      "Data Preparation: 53.2s\n",
      "Epoch: 347 (75.6s)  LR: 0.00099 Train Loss: 1.44  Valid Loss: 1.50  Valid NDCG: 0.8140\n",
      "Data Preparation: 46.5s\n",
      "Epoch: 348 (71.6s)  LR: 0.00096 Train Loss: 1.49  Valid Loss: 1.44  Valid NDCG: 0.8204\n",
      "Data Preparation: 54.3s\n",
      "Epoch: 349 (70.9s)  LR: 0.00091 Train Loss: 1.38  Valid Loss: 1.45  Valid NDCG: 0.8284\n",
      "Data Preparation: 55.1s\n",
      "Epoch: 350 (74.8s)  LR: 0.00085 Train Loss: 1.36  Valid Loss: 1.59  Valid NDCG: 0.8057\n",
      "0.7698744359630747\n",
      "Data Preparation: 47.7s\n",
      "Epoch: 351 (70.1s)  LR: 0.00078 Train Loss: 1.36  Valid Loss: 1.44  Valid NDCG: 0.8224\n",
      "Data Preparation: 47.1s\n",
      "Epoch: 352 (73.6s)  LR: 0.00070 Train Loss: 1.39  Valid Loss: 1.47  Valid NDCG: 0.8098\n",
      "Data Preparation: 48.2s\n",
      "Epoch: 353 (72.2s)  LR: 0.00061 Train Loss: 1.30  Valid Loss: 1.48  Valid NDCG: 0.8130\n",
      "Data Preparation: 51.5s\n",
      "Epoch: 354 (70.6s)  LR: 0.00052 Train Loss: 1.33  Valid Loss: 1.46  Valid NDCG: 0.8197\n",
      "Data Preparation: 53.1s\n",
      "Epoch: 355 (72.9s)  LR: 0.00042 Train Loss: 1.27  Valid Loss: 1.47  Valid NDCG: 0.8221\n",
      "0.7675941396024516\n",
      "Data Preparation: 48.1s\n",
      "Epoch: 356 (75.1s)  LR: 0.00033 Train Loss: 1.31  Valid Loss: 1.60  Valid NDCG: 0.7934\n",
      "Data Preparation: 47.8s\n",
      "Epoch: 357 (74.8s)  LR: 0.00025 Train Loss: 1.30  Valid Loss: 1.46  Valid NDCG: 0.8194\n",
      "Data Preparation: 50.4s\n",
      "Epoch: 358 (70.2s)  LR: 0.00017 Train Loss: 1.30  Valid Loss: 1.39  Valid NDCG: 0.8322\n",
      "Data Preparation: 56.9s\n",
      "Epoch: 359 (71.9s)  LR: 0.00010 Train Loss: 1.28  Valid Loss: 1.48  Valid NDCG: 0.8130\n",
      "Data Preparation: 50.6s\n",
      "Epoch: 360 (73.0s)  LR: 0.00005 Train Loss: 1.29  Valid Loss: 1.43  Valid NDCG: 0.8131\n",
      "0.7616029056774741\n",
      "Data Preparation: 51.8s\n",
      "Epoch: 361 (74.3s)  LR: 0.00002 Train Loss: 1.34  Valid Loss: 1.60  Valid NDCG: 0.7846\n",
      "Data Preparation: 46.7s\n",
      "Epoch: 362 (76.2s)  LR: 0.00000 Train Loss: 1.38  Valid Loss: 1.43  Valid NDCG: 0.8248\n",
      "Data Preparation: 49.2s\n",
      "Epoch: 363 (72.5s)  LR: 0.00000 Train Loss: 1.32  Valid Loss: 1.38  Valid NDCG: 0.8285\n",
      "Data Preparation: 48.6s\n",
      "Epoch: 364 (70.4s)  LR: 0.00002 Train Loss: 1.34  Valid Loss: 1.56  Valid NDCG: 0.8053\n",
      "Data Preparation: 49.1s\n",
      "Epoch: 365 (69.3s)  LR: 0.00005 Train Loss: 1.26  Valid Loss: 1.37  Valid NDCG: 0.8259\n",
      "0.7869963625578096\n",
      "Data Preparation: 50.9s\n",
      "Epoch: 366 (77.0s)  LR: 0.00010 Train Loss: 1.28  Valid Loss: 1.54  Valid NDCG: 0.8086\n",
      "Data Preparation: 44.7s\n",
      "Epoch: 367 (71.1s)  LR: 0.00017 Train Loss: 1.25  Valid Loss: 1.34  Valid NDCG: 0.8411\n",
      "Data Preparation: 48.9s\n",
      "Epoch: 368 (71.6s)  LR: 0.00025 Train Loss: 1.29  Valid Loss: 1.42  Valid NDCG: 0.8172\n",
      "Data Preparation: 49.2s\n",
      "Epoch: 369 (71.5s)  LR: 0.00033 Train Loss: 1.28  Valid Loss: 1.46  Valid NDCG: 0.8169\n",
      "Data Preparation: 48.7s\n",
      "Epoch: 370 (73.2s)  LR: 0.00042 Train Loss: 1.32  Valid Loss: 1.48  Valid NDCG: 0.8087\n",
      "0.7347901005920897\n",
      "Data Preparation: 52.6s\n",
      "Epoch: 371 (76.4s)  LR: 0.00052 Train Loss: 1.32  Valid Loss: 1.52  Valid NDCG: 0.8078\n",
      "Data Preparation: 47.8s\n",
      "Epoch: 372 (73.0s)  LR: 0.00061 Train Loss: 1.33  Valid Loss: 1.61  Valid NDCG: 0.7936\n",
      "Data Preparation: 48.4s\n",
      "Epoch: 373 (74.4s)  LR: 0.00070 Train Loss: 1.36  Valid Loss: 1.50  Valid NDCG: 0.8084\n",
      "Data Preparation: 46.3s\n",
      "Epoch: 374 (72.8s)  LR: 0.00078 Train Loss: 1.39  Valid Loss: 1.59  Valid NDCG: 0.7930\n",
      "Data Preparation: 51.6s\n",
      "Epoch: 375 (71.7s)  LR: 0.00085 Train Loss: 1.38  Valid Loss: 1.62  Valid NDCG: 0.7888\n",
      "0.7784063693923371\n",
      "Data Preparation: 51.9s\n",
      "Epoch: 376 (72.8s)  LR: 0.00091 Train Loss: 1.38  Valid Loss: 1.26  Valid NDCG: 0.8487\n",
      "Data Preparation: 52.4s\n",
      "Epoch: 377 (73.9s)  LR: 0.00096 Train Loss: 1.39  Valid Loss: 1.50  Valid NDCG: 0.8164\n",
      "Data Preparation: 49.7s\n",
      "Epoch: 378 (75.7s)  LR: 0.00099 Train Loss: 1.47  Valid Loss: 1.62  Valid NDCG: 0.7790\n",
      "Data Preparation: 50.4s\n",
      "Epoch: 379 (73.4s)  LR: 0.00100 Train Loss: 8.54  Valid Loss: 1.70  Valid NDCG: 0.7792\n",
      "Data Preparation: 50.0s\n",
      "Epoch: 380 (73.7s)  LR: 0.00099 Train Loss: 1.67  Valid Loss: 1.64  Valid NDCG: 0.7877\n",
      "0.736780471025118\n",
      "Data Preparation: 50.1s\n",
      "Epoch: 381 (72.4s)  LR: 0.00097 Train Loss: 1.61  Valid Loss: 1.54  Valid NDCG: 0.7997\n",
      "Data Preparation: 49.1s\n",
      "Epoch: 382 (71.5s)  LR: 0.00093 Train Loss: 1.51  Valid Loss: 1.57  Valid NDCG: 0.7901\n",
      "Data Preparation: 51.1s\n",
      "Epoch: 383 (70.1s)  LR: 0.00088 Train Loss: 1.47  Valid Loss: 1.54  Valid NDCG: 0.7994\n",
      "Data Preparation: 53.9s\n",
      "Epoch: 384 (74.0s)  LR: 0.00081 Train Loss: 1.50  Valid Loss: 1.49  Valid NDCG: 0.8139\n",
      "Data Preparation: 49.8s\n",
      "Epoch: 385 (73.1s)  LR: 0.00073 Train Loss: 1.41  Valid Loss: 1.36  Valid NDCG: 0.8344\n",
      "0.803791362474717\n",
      "Data Preparation: 49.1s\n",
      "Epoch: 386 (73.7s)  LR: 0.00064 Train Loss: 1.40  Valid Loss: 1.65  Valid NDCG: 0.7887\n",
      "Data Preparation: 50.0s\n",
      "Epoch: 387 (73.6s)  LR: 0.00055 Train Loss: 1.42  Valid Loss: 1.49  Valid NDCG: 0.8241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Preparation: 52.4s\n",
      "Epoch: 388 (72.6s)  LR: 0.00045 Train Loss: 1.39  Valid Loss: 1.53  Valid NDCG: 0.7967\n",
      "Data Preparation: 49.7s\n",
      "Epoch: 389 (72.0s)  LR: 0.00036 Train Loss: 1.34  Valid Loss: 1.35  Valid NDCG: 0.8332\n",
      "Data Preparation: 54.4s\n",
      "Epoch: 390 (72.0s)  LR: 0.00027 Train Loss: 1.34  Valid Loss: 1.50  Valid NDCG: 0.8183\n",
      "0.7319469278903019\n",
      "Data Preparation: 54.4s\n",
      "Epoch: 391 (75.8s)  LR: 0.00019 Train Loss: 1.32  Valid Loss: 1.40  Valid NDCG: 0.8228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-3344:\n",
      "Process ForkPoolWorker-3342:\n",
      "Process ForkPoolWorker-3339:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-033c6fab00ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mPrepare\u001b[0m \u001b[0mTraining\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mValidation\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     '''\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mjob\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mvalid_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-033c6fab00ca>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mPrepare\u001b[0m \u001b[0mTraining\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mValidation\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     '''\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mjob\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mvalid_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-3340:\n",
      "Process ForkPoolWorker-3343:\n",
      "Process ForkPoolWorker-3341:\n",
      "Process ForkPoolWorker-3338:\n",
      "Process ForkPoolWorker-3337:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziniu/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziniu/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziniu/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziniu/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ziniu/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziniu/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ziniu/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ziniu/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ziniu/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ziniu/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ziniu/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ziniu/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/ziniu/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ziniu/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ziniu/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/ziniu/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ziniu/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/ziniu/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ziniu/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"<ipython-input-4-4a77f845e494>\", line 17, in pf_sample\n",
      "    inp = {'paper': pids, 'field': fids}, sampled_depth = 4, sampled_number = 128)\n",
      "  File \"/home/ziniu/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ziniu/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"<ipython-input-4-4a77f845e494>\", line 17, in pf_sample\n",
      "    inp = {'paper': pids, 'field': fids}, sampled_depth = 4, sampled_number = 128)\n",
      "  File \"/home/ziniu/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"<ipython-input-4-4a77f845e494>\", line 17, in pf_sample\n",
      "    inp = {'paper': pids, 'field': fids}, sampled_depth = 4, sampled_number = 128)\n",
      "  File \"/home/ziniu/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"<ipython-input-4-4a77f845e494>\", line 17, in pf_sample\n",
      "    inp = {'paper': pids, 'field': fids}, sampled_depth = 4, sampled_number = 128)\n",
      "  File \"../utils.py\", line 284, in sample_subgraph\n",
      "    if decode(source_key)[0] in tesrt:\n",
      "  File \"/home/ziniu/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"<ipython-input-4-4a77f845e494>\", line 17, in pf_sample\n",
      "    inp = {'paper': pids, 'field': fids}, sampled_depth = 4, sampled_number = 128)\n",
      "  File \"../utils.py\", line 284, in sample_subgraph\n",
      "    if decode(source_key)[0] in tesrt:\n",
      "  File \"<ipython-input-4-4a77f845e494>\", line 17, in pf_sample\n",
      "    inp = {'paper': pids, 'field': fids}, sampled_depth = 4, sampled_number = 128)\n",
      "  File \"../utils.py\", line 284, in sample_subgraph\n",
      "    if decode(source_key)[0] in tesrt:\n",
      "  File \"/home/ziniu/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 352, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"../utils.py\", line 284, in sample_subgraph\n",
      "    if decode(source_key)[0] in tesrt:\n",
      "  File \"../utils.py\", line 182, in decode\n",
      "    return np.array([s[:idx], s[idx+1:]], dtype=float)\n",
      "  File \"<ipython-input-4-4a77f845e494>\", line 17, in pf_sample\n",
      "    inp = {'paper': pids, 'field': fids}, sampled_depth = 4, sampled_number = 128)\n",
      "  File \"../utils.py\", line 284, in sample_subgraph\n",
      "    if decode(source_key)[0] in tesrt:\n",
      "  File \"../utils.py\", line 182, in decode\n",
      "    return np.array([s[:idx], s[idx+1:]], dtype=float)\n",
      "  File \"../utils.py\", line 284, in sample_subgraph\n",
      "    if decode(source_key)[0] in tesrt:\n",
      "  File \"../utils.py\", line 182, in decode\n",
      "    return np.array([s[:idx], s[idx+1:]], dtype=float)\n",
      "  File \"/home/ziniu/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"../utils.py\", line 182, in decode\n",
      "    return np.array([s[:idx], s[idx+1:]], dtype=float)\n",
      "KeyboardInterrupt\n",
      "  File \"../utils.py\", line 284, in sample_subgraph\n",
      "    if decode(source_key)[0] in tesrt:\n",
      "  File \"../utils.py\", line 182, in decode\n",
      "    return np.array([s[:idx], s[idx+1:]], dtype=float)\n",
      "KeyboardInterrupt\n",
      "  File \"../utils.py\", line 182, in decode\n",
      "    return np.array([s[:idx], s[idx+1:]], dtype=float)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ziniu/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"../utils.py\", line 182, in decode\n",
      "    return np.array([s[:idx], s[idx+1:]], dtype=float)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ziniu/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "stats = []\n",
    "pool = mp.Pool(8)\n",
    "process_ids = np.arange(batch_num // 8)\n",
    "st = time.time()\n",
    "jobs = prepare_data(pool, process_ids)\n",
    "train_step = 2500\n",
    "best_val   = 0\n",
    "res = []\n",
    "criterion = nn.KLDivLoss(reduction='batchmean')\n",
    "for epoch in np.arange(epoch_num)+1:\n",
    "    '''\n",
    "        Prepare Training and Validation Data\n",
    "    '''\n",
    "    train_data = [job.get() for job in jobs[:-1]]\n",
    "    valid_data = jobs[-1].get()\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    pool = mp.Pool(8)\n",
    "    jobs = prepare_data(pool, process_ids)\n",
    "    et = time.time()\n",
    "    print('Data Preparation: %.1fs' % (et - st))\n",
    "    \n",
    "    \n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    for batch in np.arange(8):\n",
    "        for node_feature, node_type, edge_time, edge_index, edge_type, field_ids, paper_ids, ylabel in train_data:\n",
    "            node_rep = gnn.forward(node_feature.to(device), edge_index.to(device), edge_type.to(device))\n",
    "            res  = classifier.forward(node_rep[paper_ids])\n",
    "            loss = criterion(res, ylabel.to(device))\n",
    "            optimizer.zero_grad() \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_losses += [loss.cpu().detach().tolist()]\n",
    "            train_step += 1\n",
    "            scheduler.step(train_step)\n",
    "    '''\n",
    "        Valid\n",
    "    '''\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        node_feature, node_type, edge_time, edge_index, edge_type, field_ids, paper_ids, ylabel = valid_data\n",
    "        node_rep = gnn.forward(node_feature.to(device), edge_index.to(device), edge_type.to(device))\n",
    "        res  = classifier.forward(node_rep[paper_ids])\n",
    "        loss = criterion(res, ylabel.to(device))\n",
    "        valid_res = []\n",
    "\n",
    "        for ai, bi in zip(ylabel, res.argsort(descending = True)):\n",
    "            valid_res += [ai[bi].tolist()]\n",
    "        valid_ndcg = np.average([ndcg_at_k(resi, len(resi)) for resi in valid_res])\n",
    "        if valid_ndcg > best_val:\n",
    "            best_val = valid_ndcg\n",
    "            torch.save(model, './save/rgcn.pt')\n",
    "        st = time.time()\n",
    "        print((\"Epoch: %d (%.1fs)  LR: %.5f Train Loss: %.2f  Valid Loss: %.2f  Valid NDCG: %.4f\") % \\\n",
    "              (epoch, (st-et), optimizer.param_groups[0]['lr'], np.average(train_losses), loss.cpu().detach().tolist(),\\\n",
    "              valid_ndcg))\n",
    "        stats += [[np.average(train_losses), loss.cpu().detach().tolist()]]\n",
    "        if epoch % 5 == 0:\n",
    "            '''\n",
    "                Test\n",
    "            '''\n",
    "            _time = np.random.choice(list(test_papers.keys()))\n",
    "            node_feature, node_type, edge_time, edge_index, edge_type, field_ids, paper_ids, ylabel = pf_sample(np.random.randint(2 ** 32 - 1), test_papers, \\\n",
    "                                                           test_pairs, test_range, batch_size, test=True)\n",
    "            paper_rep = gnn.forward(node_feature.to(device), edge_index.to(device), edge_type.to(device))[paper_ids]\n",
    "            res = classifier.forward(paper_rep)\n",
    "            test_res = []\n",
    "            for ai, bi in zip(ylabel, res.argsort(descending = True)):\n",
    "                test_res += [ai[bi].tolist()]\n",
    "            test_ndcg = np.average([ndcg_at_k(resi, len(resi)) for resi in test_res])\n",
    "            print(test_ndcg)\n",
    "    del train_data, valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "stats = np.array(stats)\n",
    "plt.plot(stats[:,0])\n",
    "plt.plot(stats[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = torch.load('./save/rgcn.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7532831683622845 0.06120572204416289\n",
      "0.7221447213350138 0.12264175751145479\n"
     ]
    }
   ],
   "source": [
    "best_model.eval()\n",
    "gnn, classifier = best_model\n",
    "with torch.no_grad():\n",
    "    test_res = []\n",
    "    for _ in range(10):\n",
    "        _time = np.random.choice(list(test_papers.keys()))\n",
    "        node_feature, node_type, edge_time, edge_index, edge_type, field_ids, paper_ids, ylabel = pf_sample(np.random.randint(2 ** 32 - 1), test_papers, \\\n",
    "                                                       test_pairs, test_range, batch_size, test=True)\n",
    "        paper_rep = gnn.forward(node_feature.to(device), edge_index.to(device), edge_type.to(device))[paper_ids]\n",
    "        res = classifier.forward(paper_rep)\n",
    "        for ai, bi in zip(ylabel, res.argsort(descending = True)):\n",
    "            test_res += [ai[bi].tolist()]\n",
    "    test_ndcg = [ndcg_at_k(resi, len(resi)) for resi in test_res]\n",
    "    print(np.average(test_ndcg), np.var(test_ndcg))\n",
    "    test_mrr = mean_reciprocal_rank(test_res)\n",
    "    print(np.average(test_mrr), np.var(test_mrr))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
